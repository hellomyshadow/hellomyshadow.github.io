<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="敢做就能赢！">
<meta property="og:type" content="website">
<meta property="og:title" content="大麦田程序猿">
<meta property="og:url" content="http://hellomyshadow.github.io/page/3/index.html">
<meta property="og:site_name" content="大麦田程序猿">
<meta property="og:description" content="敢做就能赢！">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="大麦田程序猿">
<meta name="twitter:description" content="敢做就能赢！">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://hellomyshadow.github.io/page/3/">





  <title>大麦田程序猿</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">大麦田程序猿</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/10/05/爬虫基础-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/05/爬虫基础-2/" itemprop="url">爬虫基础-2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-05T00:00:00+08:00">
                2017-10-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="cookielib"><a href="#cookielib" class="headerlink" title="cookielib"></a>cookielib</h2><pre><code>cookielib是自动处理cookie的模块，对应urllib2的处理器：HTTPCookieProcessor
    1. cookielib：主要作用是提供用于存储cookie的对象；
    2. HTTPCookieProcessor：处理cookie对象，并构建Handler对象；
1. cookielib的主要对象：CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar
    1. CookieJar：管理HTTP cookie值、存储HTTP请求生成的cookie、向发送的HTTP请求添加
    cookie的对象；整个cookie都存储在内存中，CookieJar实例被垃圾回收后，cookie也将丢失；
    2. FileCookieJar(filename, delayload=None, policy=None)：CookieJar的子类，
    检索cookie信息并存储到文件中，delayload为True时支持延迟访问文件，只有在需要时才读取
    文件或者在文件中存储数据；
    3. MozillaCookieJar(filename,delayload=None,policy=None)：FileCookieJar的子类，
    用于兼容Mozilla浏览器的FileCookieJar；
    4. LWPCookieJar(filename, delayload=None, policy=None)：FileCookieJar的子类，
    用于兼容libwww-perl标准Set-Cookie3文件格式的FileCookieJar。
2. HTTPCookieProcessor
    1. 构建能保存cookie的处理器和Opener：
        cookie = cookielib.CookieJar()
        handler = urllib2.HTTPCookieProcessor(cookie)
        opener = urllib2.build_opener(handler)
    2. 发送登录请求，保存生成的cookie：
        url = &apos;http://www.renren.com/PLogin.do&apos; --&gt; 老版人人网没有动态token验证
        data = {&apos;email&apos;: &apos;人人网用户名&apos;, &apos;password&apos;: &apos;人人网密码&apos;}
        request = urllib2.Request(url, data=urllib.urlencode(data), headers)
        response = opener.open(request) --&gt; 发送POST请求，如果登录成功，则保存Cookie
    3. 使用cookie访问个人主页
        pro_url = &apos;http://www.renren.com/966033501/profile&apos; --&gt; 人人网个人主页
        pro_request = urllib2.Request(profile_url, headers)
        res_pro = opener.open(pro_request) --&gt; 携带登录后的Cookie，再次发送请求
    4. 输出标准格式的Cookie：cookieStr = &quot;&quot;
        for item in cookie:
            cookieStr = cookieStr + item.name + &quot;=&quot; + item.value + &quot;;&quot;
        print cookieStr[:-1]
3. 对于FileCookieJar，发送请求之后，执行cookie.save()，才能保存Cookie到本地文件；
    1. cookie = cookielib.MozillaCookieJar()
    2. cookie.load(&apos;cookie.txt&apos;)：从文件中读取Cookie到内存中。
4. 模拟登录的注意点：
    1. 登录一般都会先有一个HTTP GET，拉取一些信息及获得Cookie，然后再HTTP POST登录；
    2. HTTP POST登录的链接有可能是动态的，从GET返回的信息中获取；
    3. password有些是明文发送，有些是加密后发送；有些网站甚至采用动态加密的，同时包括了
    很多其他数据的加密信息，只能通过查看JS源码获得加密算法，再去破解加密，非常困难；
    4. 大多数网站的登录整体流程是类似的，可能有些细节不一样，不能保证每个网站都能登录成功。
</code></pre><h2 id="URLError与HTTPError"><a href="#URLError与HTTPError" class="headerlink" title="URLError与HTTPError"></a>URLError与HTTPError</h2><pre><code>urlopen()/opener.open()发出请求时，如果urlopen()/opener.open()不能处理这个response，
就产生错误，常见的包括URLError、HTTPError
1. URLError产生的主要原因：没有网络连接、服务器连接失败、找不到指定的服务器；
    1. 在发送请求时，对urlopen()/opener.open()使用try-except捕获相应的异常；
    2. urlopen error [Errno 8]：未找到指定的服务器。
2. HTTPError是URLError的子类，服务器响应的response包含响应码，但urllib2会自动处理重定向
   的页面(3开头的响应码)，100-299表示成功，所以只能看到400-599的错误码；
3. try-except优先处理HTTPError，然后处理URLError：
    try:
        urllib2.urlopen(requset)
    except urllib2.HTTPError, err:
        print err.code
    except urllib2.URLError, err:
        print err
</code></pre><h2 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h2><pre><code>requests模块的底层是urllib3，继承了urllib2的所有特性，号称：HTTP for Humans
1. requests支持HTTP连接保持和连接池，支持使用cookie保持会话，支持文件上传；
2. 支持自动确定响应内容的编码，支持国际化的URL和POST数据自动编码；
3. requests能完全满足当前网络的需求，支持python2.6-3.x，而且能运行在PyPy环境；
4. 安装：pip install requests，easy_install requests
</code></pre><h3 id="GET和POST"><a href="#GET和POST" class="headerlink" title="GET和POST"></a>GET和POST</h3><pre><code>1. GET请求：
    1. response = requests.get(&quot;http://www.baidu.com/&quot;)
    2. response = requests.request(&quot;get&quot;, &quot;http://www.baidu.com/&quot;)
2. POST请求：response = requests.post(url, data={&apos;k1&apos;:&apos;v1&apos;}, heanders)
3. 添加请求头与请求参数
    1. requests.get(url, params={&apos;k1&apos;:&apos;v1&apos;}, headers={&apos;k1&apos;:&apos;v1&apos;})
    2. params：GET请求需要传递的参数；    headers：请求头；
    3. params和headers都会被自动国际化编码，不需要手动处理。
4. response.url：查看完整的URL；    response.status_code：查看响应码；
5. response.text：获取响应内容，一般为Unicode编码的数据；
    1. response.encoding：查看响应内容的字符编码；
    2. response.encoding=&apos;utf-8&apos;：修改响应数据的编码，response.text也会使用此编码；
    3. 在写入文件时，如果报编码错误：UnicodeEncodeError:&apos;ascii&apos; codec can&apos;t ...
    则使用&apos;utf-8&apos;编码，再写入：
    with open(&apos;res.txt&apos;, &apos;w&apos;) as f:
        f.write(response.text.encode(&apos;utf-8&apos;))
6. response.content：获取原始二进制字节流形式的响应内容，可用来保存图片等二进制文件；
7. response.json()：如果响应的是JSON数据，可以直接获取。
</code></pre><h3 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h3><pre><code>1. 配置单个请求的代理：
    res = requests.get(url, proxies = {&apos;http&apos;:&apos;代理URL&apos;, &apos;https&apos;:&apos;代理URL&apos;})
2. 统一配置代理：在本地环境变量中配置HTTP_PROXY和HTTPS_PROXY
    export HTTP_PROXY=&quot;http://12.34.56.79:9527&quot;
    export HTTPS_PROXY=&quot;https://12.34.56.79:9527&quot;
3. 私密代理验证账号密码
    response = requests.get(url, proxies={ &quot;代理类型&quot;: &quot;用户名:密码@Ip:Port&quot; })
4. web客户端验证账号密码：response = requests.get(url, auth=(&quot;用户名&quot;, &quot;密码&quot;))
</code></pre><h3 id="Cookie与Sission"><a href="#Cookie与Sission" class="headerlink" title="Cookie与Sission"></a>Cookie与Sission</h3><pre><code>1. Cookie
    1. cookiejar = response.cookies：如果一个请求中包含Cookie，则获取到CookieJar对象；
    2. cookiedict = requests.utils.dict_from_cookiejar(cookiejar)：转为字典形式；
2. Sission
    1. 在requests中，Session对象是很常用的，它代表一次用户会话，Client连接Server开始，
    到Client断开连接；
    2. 会话能让Client在跨请求时保持某些参数，比如：在某一个Session实例发出的所有请求之间
    保持Cookie。
3. Session模拟Client登录
    ssion = requests.session() --&gt; 创建Session对象，保存Cookie；
    ssion.post(url, data={ 账号密码等参数 }, headers)
    response = ssion.get(url) --&gt; 登录成功后，ssion中已经保存了cookie，可以直接请求；
</code></pre><h3 id="HTTPS请求SSL证书"><a href="#HTTPS请求SSL证书" class="headerlink" title="HTTPS请求SSL证书"></a>HTTPS请求SSL证书</h3><pre><code>1. verify=True：表示发起HTTPS请求时，检查主机的SSL证书，默认为True；
    response = requests.get(&quot;https://www.baidu.com/&quot;, verify=True)
2. 如果SSL证书验证不通过/不信任Server的安全证书，如https://www.12306.cn，则报SSLError
    requests.get(&quot;https://www.12306.cn/mormhweb/&quot;, verify = False) --&gt; 跳过验证
</code></pre><h2 id="提取数据"><a href="#提取数据" class="headerlink" title="提取数据"></a>提取数据</h2><pre><code>爬取页面的内容一般分为两部分：非结构化数据和结构化数据；
1. 非结构化数据：先有数据，再有结构；
    1. 文本、电话号码、邮箱地址的处理方式：正则表达式；
    2. HTML文件：正则表达式、XPath、CSS选择器。
2. 结构化数据：先有结构，再有数据；
    1. JSON的处理方式：JSONPath、转化成Python类型进行操作(Json类)；
    2. XML：转化成Python类型(xmltodict)、XPath、CSS选择器、正则表达式。
3. 抓取速度：正则 &gt; XPath &gt; CSS选择器，但CSS选择器的使用时最简单的。
</code></pre><h3 id="XPath"><a href="#XPath" class="headerlink" title="XPath"></a>XPath</h3><pre><code>1. XPath：是一门在XML文档中查找信息的语言，可用来在XML文档中对元素和属性进行遍历；
    1. /div：从根节点开始匹配&lt;div&gt;；    //div：从任意节点开始匹配&lt;div&gt;；
    2. //div[@class=&quot;threadlist&quot;]：从任意目录开始、根据指定的属性进行匹配div节点；
    3. //div/a：从任意节点开始匹配div节点，然后匹配&lt;div&gt;的直接子节点&lt;a&gt;；
    4. //div//a：从任意节点开始匹配div节点，然后匹配&lt;div&gt;下任意层级的子节点&lt;a&gt;；
    5. //div//a[@class=&quot;thie&quot;]/@href：获取匹配&lt;a&gt;的href属性值；
    6. //div//@href：直接匹配&lt;div&gt;下的所有节点的href属性值；
    7. //div[@class=&quot;li_txt&quot;]/h3/text()：获取&lt;h3&gt;的文本内容
    8. .：选取当前节点；    ..：选取当前节点的父节点；    *：选取所有节点；    |：多选。
2. lxml：将HTML文档解析为HTML DOM模型，即把HTML转为XML；该模块需要手动安装；
    1. from lxml import etree
    2. html = urllib2.urlopen(request).read()
    3. xml = etree.HTML(html)
    4. content = xml.xpath(&apos;XPath的查找规则&apos;) --&gt; 返回一个列表，类似于正则findall()
3. content = xml.xpath(&apos;//div/a&apos;)
    1. content[0].tag：获取标签名；    content[0].text：获取标签内的字符串文本；
    2. content[0].get(&apos;href&apos;)：获取指定的属性值；
    3. content[0].xpath(&apos;./span&apos;)：对&apos;//div/a&apos;匹配的内容进一步匹配，//div/a/span
4. 不同的WebServer会针对不同的Client发送不同的数据，一般IE是标准格式，使用XPath解析时，
   通常使用IE的User-Agent作为请求头；
5. 如果当前层级查找不到，则继续向上取父节点，如爬取百度贴吧的帖子链接：
    1. 无效的XPath规则：
    //div[@class=&quot;threadlist_lz clearfix&quot;]/div/a[@class=&quot;j_th_tit&quot;]/@href
    //div[@class=&quot;threadlist_lz clearfix&quot;]//a[@class=&quot;j_th_tit&quot;]/@href
    2. 有效的XPath规则：//div[@class=&quot;t_con cleafix&quot;]/div/div/div/a/@href
6. 强大的模糊查询：
    //div[contains(@id, &quot;qiush_tag_&quot;)]，匹配id属性值中包含&quot;qiush&quot;的&lt;div&gt;
</code></pre><h3 id="BeautifulSoup4"><a href="#BeautifulSoup4" class="headerlink" title="BeautifulSoup4"></a>BeautifulSoup4</h3><pre><code>CSS选择器：BeautifulSoup4，也是一个HTML/XML的解析器，主要用于解析和提取HTML/XML数据；
    1. lxml只会局部遍历，而BeautifulSoup基于HTML DOM，会载入整个文档，解析整个DOM树，
    因此时间和内存开销都会大很多，所以性能要低于lxml；
    2. BeautifulSoup解析HTML比较简单，支持CSS选择器、Python标准库中的HTML解析器，
    也支持lxml的XML解析器；
    3. BS3目前已经停止开发，推荐使用BS4：pip install beautifulsoup4
1. from bs4 import BeautifulSoup
    1. soup = BeautifulSoup(html) --&gt; 由爬取的HTML创建BeautifulSoup对象
    2. BeautifulSoup(open(&apos;index.html&apos;)) --&gt; 打开本地HTML文件创建BeautifulSoup对象
    3. soup = BeautifulSoup(html, &apos;lxml&apos;)：指定解析器为lxml，如果没有显示指定，默认
    使用当前系统的最佳可用HTML解析器，不同的系统/虚拟环境中，使用不同的解析器造成行为不同；
    4. print soup.prettify() --&gt; 格式化输出soup对象的内容；
2. BeautifulSoup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象，所有对象
   可以归纳为4种：BeautifulSoup、Tag、NavigableString、Comment
</code></pre><h4 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h4><pre><code>1. soup.element：根据标签名获取标签对象，且只返回第一个，对象类型为bs4.element.Tag
    1. soup.title：&lt;title&gt; ... &lt;/title&gt;
    2. soup.head：&lt;head&gt;&lt;title&gt; ... &lt;/title&gt;&lt;/head&gt;
    3. soup.element.get_text()：获取标签内的字符串文本。
2. 属性name
    1. BeautifulSoup表示的是一个文档的内容，它是一个特殊的Tag，soup.name：[document]
    2. soup.element.name：返回标签名，如soup.title.name：title
3. 属性attrs：获取标签的所有属性组成的字典，如果该标签没有使用属性，则返回空字典；
    1. 标签的class属性可以指定多个值，以列表的形式返回；
    2. soup.p.attrs：获取&lt;p&gt;的所有属性，{&apos;class&apos;: [&apos;cls1&apos;, &apos;cls2&apos;], &apos;name&apos;: &apos;p1&apos;}
4. soup.p[&apos;attr&apos;]/soup.p.get(&apos;attr&apos;)：根据标签的属性名获取属性值；
    1. soup.p.get(&apos;name&apos;)：获取&lt;p&gt;的name属性值；
    2. 如果标签属性有多个属性值，如class属性，则返回一个属性值列表。
5. soup.p[&apos;class&apos;] = &apos;cls3&apos;：修改&lt;p&gt;的class属性值；
6. del soup.p[&apos;class&apos;]：删除&lt;p&gt;的class属性。
</code></pre><h4 id="NavigableString"><a href="#NavigableString" class="headerlink" title="NavigableString"></a>NavigableString</h4><pre><code>&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;
    1. soup.p.string：获取&lt;p&gt;&lt;/p&gt;的文本内容，The Dormouse&apos;s story
    2. type(soup.p.string)：&lt;class &apos;bs4.element.NavigableString&apos;&gt;
&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;
    1. Comment是一个特殊NavigableString，其输出的内容不包括注释符号；
    2. soup.a.string：获取&lt;a&gt;&lt;/a&gt;的文本内容，Elsie
    3. type(soup.a.string)：&lt;class &apos;bs4.element.Comment&apos;&gt;
&lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;child1&lt;/b&gt;&lt;b&gt;child2&lt;/b&gt;&lt;/p&gt;
    soup.p.string：None，即当标签内只有一个直接子节点，或者没有子节点时，string才有效。
</code></pre><h4 id="遍历文档树"><a href="#遍历文档树" class="headerlink" title="遍历文档树"></a>遍历文档树</h4><pre><code>1. soup.element.contents：以列表的形式输出element的子节点的Tag对象，包括换行符\n等；
2. soup.element.children：返回一个列表迭代器listiterator，遍历获取所有子节点的Tag对象；
3. soup.element.descendants：content和children只遍历一次直接子节点，而descendants会
   递归遍历所有子节点，包括标签内的文本，返回一个生成器对象generator，遍历获取所有Tag对象；
</code></pre><h4 id="搜索文档树"><a href="#搜索文档树" class="headerlink" title="搜索文档树"></a>搜索文档树</h4><pre><code>soup.find(name, attrs, recursive, text, **kwargs)：返回第一个匹配标签的Tag对象；
soup.find_all(name, attrs, recursive, text, **kwargs)：返回一个列表；
1. 参数name：只针对标签，会自动过滤字符串文本；
    1. find_all(&apos;a&apos;)：返回所有&lt;a&gt;标签的Tag对象；
    2. find_all(re.compile(&apos;^b&apos;))：使用正则查找以&apos;b&apos;为开头的标签；
    3. find_all([&apos;a&apos;, &apos;b&apos;])：根据列表指定查找哪些标签。
2. 参数text：搜索标签内的字符串文本，返回匹配的字符串列表；
    1. text接受的参数与name相同：字符串、正则表达式、列表；
    2. find_all(text=re.compile(&apos;story&apos;))：匹配文档中包含&apos;story&apos;的字符串文本。
3. 参数attrs：根据标签的属性名和属性值进行查找，接收一个字典，多个键值表示条件与；
    1. find_all(attrs={&apos;id&apos;: &apos;uname&apos;})：查找id的属性值为&apos;uname&apos;的标签；
    2. find_all(attrs={&apos;class&apos;: &apos;con&apos;})：查找class的属性值中包含&apos;con&apos;的标签；
    3. find_all(attrs={&apos;name&apos;: &apos;uname&apos;, &apos;value&apos;: &apos;man&apos;})：查找name属性值为&apos;uname&apos;
    且value属性值为&apos;man&apos;的标签；
    4. find_all(&apos;h2&apos;, {&apos;class&apos;: &apos;ellip&apos;})：查找class的属性值包含&apos;ellip&apos;的&lt;h2&gt;
4. 参数kwargs：如果一个指定名字的参数不是搜索内置的参数名，则把该参数当作标签属性来搜索；
    1. find_all(id=&apos;login&apos;)：搜索id属性值为&apos;login&apos;的标签；
    2. find_all(href=re.compile(&quot;elsie&quot;))：搜索href属性值中匹配&apos;elsie&apos;的标签；
    3. find_all(id=True)：查找所有包含id属性的标签。
</code></pre><h4 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a>CSS选择器</h4><pre><code>1. soup.select()：CSS选择器搜索文档树的方法，返回Tag列表，根据定义CSS名称的方式查找；
2. 标签选择器查找，即根据标签名查找：select(&apos;a&apos;)
3. 类选择器查找：select(&apos;.content&apos;)，匹配class属性值包含&apos;content&apos;的标签；
4. id选择器查找：select(&apos;#login&apos;)，匹配id为&apos;login&apos;的标签；
5. 利用层级选择器查找：select(&apos;.cont a&apos;)，使用了con选择器的标签下的&lt;a&gt;；
6. 只查找直接子节点：select(&apos;.cont &gt; a&apos;)，使用了con选择器的标签下的直接子节点&lt;a&gt;
</code></pre><h3 id="json"><a href="#json" class="headerlink" title="json"></a>json</h3><pre><code>1. python自带有json模块，import json，用于字符串和python数据类型间的转换；
2. json.loads(str)：把Json格式字符串解码转换为Python对象；
    object --&gt; dict，array --&gt; list，string --&gt; unicode str，null --&gt; None
    true/false --&gt; True/False
    1. 如果在loads()时出错，可能是因为Json字符串的编码不是UTF-8；
    2. 对于GBK编码的字符串：json.loads(jsonstr, encoding=&quot;GBK&quot;)
    3. 如果Json字符串指定了合适的编码，但是其中又包含其他编码的字符，则需要先转换为Unicode，
    然后再指定编码格式：
    unicodeStr = jsonStr.decode(&quot;GB2312&quot;); 
    data = json.loads(unicodeStr, encoding=&quot;GB2312&quot;);
    5. 任何平台的任何编码 都能和Unicode互相转换，对于UTF-8与GBK互相转换，先把UTF-8转换成
    Unicode(decode(&quot;UTF-8&quot;))，再从Unicode转换成GBK(encode(&quot;GBK&quot;))，反之同理；
    6. decode()：将其他编码的字符串转换成Unicode编码；
    7. encode()：将Unicode编码转换成其他编码的字符串。
3. json.dumps(obj)：把Python对象转为Json字符串，list/tuple --&gt; array
    1. dumps()转换时默认使用ASCII编码，dumps(obj, ensure_ascii=False)表示禁用ASCII，
    按UTF-8编码，但如果obj中是全英文的元素，仍使用ASCII编码；
    2. chardet：一个非常优秀的编码识别模块，可通过pip安装；
    3. chardet.detect(json.dumps(obj)) --&gt; {&apos;confidence&apos;:1.0,&apos;encoding&apos;:&apos;ascii&apos;}
4. json.dump(obj, open(&apos;f.json&apos;, &apos;w&apos;), ensure_ascii=False)：转为Json后写入文件；
5. json.load(open(&quot;f.json&quot;))：读取文件中Json，转为Python对象。
</code></pre><h4 id="JSONPath"><a href="#JSONPath" class="headerlink" title="JSONPath"></a>JSONPath</h4><pre><code>XPath用于匹配XML，JSONPath用于匹配Json，安装：pip install jsonpath
1. 语法对比
    1. $：根节点 --&gt; XPath的&apos;/&apos;；        @：当前节点 --&gt; XPath的&apos;.&apos;；
    2. .或[]：取子节点；    *：匹配所有节点；    [,]：多选操作 --&gt; XPath的&apos;|&apos;；
    3. ..：从任意节点开始查找 --&gt; XPath的&apos;//&apos;；    ?()：过滤操作 --&gt; XPath的&apos;[]&apos;；
    4. []：迭代器标示，可以做简单的迭代操作，如数组下标、根据内容选值等；
    5. XPath的[index]是从1开始，而JSONPath是从0开始，&apos;//book[3]&apos; &lt;--&gt; &apos;$..book[2]&apos;
2. import jsonpath
    1. city = json.loads(html)
    2. jsonpath.jsonpath(city, &apos;$..name&apos;)：从任意节点匹配name，返回一个name值的列表.
</code></pre><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/10/03/爬虫基础-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/03/爬虫基础-1/" itemprop="url">爬虫基础-1</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-03T00:00:00+08:00">
                2017-10-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="爬虫概述"><a href="#爬虫概述" class="headerlink" title="爬虫概述"></a>爬虫概述</h2><pre><code>1. 网页的三大特征：
    1. 网页都有自己的唯一的URL进行定位；
    2. 网页都使用HTML来描述页面信息；
    3. 网页都使用HTTP/HTTPS协议传输HTML数据。
2. 爬虫的设计思路：
    1. 首先确定需要爬去的网页URL；
    2. 通过HTTP/HTTPS协议来获取对应的HTML页面；
    3. 提取HTML页面里有用的数据，如果页面中还有其他URL，则继续执行第二步。
</code></pre><h3 id="爬虫分类"><a href="#爬虫分类" class="headerlink" title="爬虫分类"></a>爬虫分类</h3><pre><code>1. 通用爬虫： 搜索引擎用的爬虫系统
    1. 目标：尽可能把互联网上的所有网页下载到本地服务器，形成备份，再对这些网页做相关
    处理(提取关键字、去广告)，最后提供一个用户检索接口；
    2. 抓取流程：选取一部分的种子URL，放到待爬取队列 --&gt; 从队列中取出这些URL，解析DNS
    得到主机IP --&gt; 到IP对应的服务器里下载HTML页面，保存到搜索引擎的本地服务器 --&gt;
    将这些URL放进已爬去队列 --&gt; 分析这些网页内容，找出网页里的其他URL，继续爬取，直至
    爬取条件结束。
    3. 搜索引擎获取一个新网站URL的方式：
        1. 主动向搜索引擎提交网址；
        2. 在其他网站设置外链，比如友情链接，搜索引擎在爬取时，会保存新的URL；
        3. 搜索引擎会和DNS服务商进行合作，可以快速收录新的网站。
    4. Robots协议：指明通用爬虫可以爬取网页的权限，一般只有大型搜索引擎的爬虫才会遵守；
    淘宝网的robots协议：https://www.taobao.com/robots.txt
    5. 工作流程：爬取网页 --&gt; 存储数据 --&gt; 内容处理 --&gt; 提供检索/排名服务
    6. 通用爬虫的缺点：
        1. 只能提供和文本相关的内容(HTML、Word、PDF...)，不能提供多媒体文件(音乐、图片、
        视频)和二进制文件(程序、脚本...)
        2. 提供的结果千篇一律，不能针对不同背景/领域的人提供不同的搜索结果；
        3. 不能理解人类的语义，只能提供关键字的检索。
2. 聚焦爬虫：爬虫程序员编写的针对某种内容的爬虫，弥补了通用爬虫的缺点。
    面向主题/需求爬虫，会针对某种特定的内容去爬取信息，而且会保证信息和需求尽可能相关。
</code></pre><h2 id="HTTP和HTTPS"><a href="#HTTP和HTTPS" class="headerlink" title="HTTP和HTTPS"></a>HTTP和HTTPS</h2><pre><code>1. HTTP协议：超文本传输协议，是一种发布与接收HTML页面的方法，默认端口号80；
2. HTTPS协议：HTTP的安全版，在HTTP下加入SSL层，默认端口号443；
    1. SSL：安全套接层，主要用于Web的安全传输协议，在传输层对网络连接进行加密；
    2. 浏览器的主要功能是向服务器发送请求，HTTP是一套计算机通过网络进行通信的规则；
    3. 网络爬虫抓取过程可以理解为：模拟浏览器操作的过程。
3. HTTP通信由两部分组成：客户端请求消息、服务器响应消息；
4. 浏览器分析Response中的HTML，发现其中还引用了其他文件，如图片、CSS文件、JS文件，
    浏览器会自动继续发送Request去获取这些资源文件。
5. URL：统一资源定位符，用于完整地描述Internet上网页和其他资源地址的一种标识方法；
    1. 格式：scheme://host[:port#]/path/.../[?query-string][#anchor]
    2. path：访问资源的路径；    query-string：参数，发送给HTTP服务器的数据；
    3. anchor：锚点，http://item.jd.com/11936.html#product-detail
    4. URL只是标识资源的位置，HTTP才是用来提交和获取资源。
</code></pre><h3 id="HTTP请求"><a href="#HTTP请求" class="headerlink" title="HTTP请求"></a>HTTP请求</h3><pre><code>请求消息的格式：请求行、请求头、空行、请求体
一个典型的HTTP请求：
    GET https://www.baidu.com/ HTTP/1.1
    Host: www.baidu.com
    Connection: keep-alive
    Upgrade-Insecure-Requests: 1
    User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit......
    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,......
    Referer: http://www.baidu.com/
    Accept-Encoding: gzip, deflate, sdch, br
    Accept-Language: zh-CN,zh;q=0.8,en;q=0.6
    Cookie: BAIDUID=04E4001F34EA74AD4601512DD3C41A7B:FG=1; BIDUPSID=......
1. 请求行：GET https://www.baidu.com/ HTTP/1.1
    1. GET：请求方法，常用GET和POST；
    2. https://www.baidu.com/：请求的URL；
    3. HTTP/1.1：HTTP协议和版本，0.9只有GET，1.0增加了POST和HEAD，1.1又新增了5种；
2. 请求头
    1. Host：指定请求资源的主机和端口号，通常属于URL的一部分；
    2. Connection：表示客户端与服务器链接的类型，HTTP1.1默认值为keep-alive
        1. 如果Server支持keep-alive，则回复一个包含Connection:keep-alive的响应，
        不关闭链接；否则回复一个包含Connection:close的响应，关闭链接；
        2. keep-alive在很多情况下能够重用连接，减少资源消耗，缩短响应时间。
    3. Upgrade-Insecure-Requests：升级不安全的请求，会在加载Http资源时自动替换成
        Https请求，让浏览器不再显示Https页面中的Http请求警报；
        HTTPS是以安全为目标的HTTP通道，所以在HTTPS承载的页面上不允许出现HTTP请求，
        一旦出现就会提示或报错。
    4. User-Agent：客户浏览器的名称，对爬虫而言，是最重要的参数，用于伪装请求者；
    5. Accept：client可以接受的MIME文件类型，Server根据它判断并返回适当的文件格式；
        1. Accept: */* --&gt; 表示什么都可以接收；
        2. Accept: image/gif --&gt; 客户端希望接受GIF图像格式的资源；
        3. Accept: text/html --&gt; 客户端希望接受html文本；
        4. Accept: text/html, application/xhtml+xml;q=0.9, image/*;q=0.8
        表示浏览器支持的MIME类型分别是html文本、xhtml和xml文档、所有的图像格式资源。
        5. q：权重系数，范围0-1，值越大，请求越倾向于获得其“;”之前的类型表示的内容。
        若没有指定q值，则默认为1，按从左到右排序顺序；若被赋值为0，则表示浏览器不接受
        此内容类型。
        6. text：用于标准化地表示的文本信息，文本消息可以是多种字符集/多种格式的；
        7. application：用于传输应用程序数据/二进制数据。
    6. Referer：表明产生请求的网页来自于哪个URL，它可以用来跟踪Web请求来自哪个页面、
        是从什么网站来的等等；
        有时候遇到下载某网站图片，需要对应的Referer，否则无法下载图片，是因为他们做了
        防盗链，原理就是根据Referer去判断是否是本网站的地址，如果不是，则拒绝。
    7. Accept-Encoding：文件的编解码格式，若不指定，Server不会压缩，仍响应原始数据；
        1. 编码方式不同于文件格式，它是为了压缩文件、以加速文件传输；
        2. 浏览器接收到Response后，先解码，再检查文件格式。
    8. Accept-Language：client支持的语言，en/en-us表示英语，zh/zh-cn表示中文；
    9. Accept-Charset：字符编码，如果不指定，则默认client支持所有字符集；
        1. ISO8859-1：通常叫做Latin-1，英文浏览器的默认值是ISO-8859-1
        2. gb2312：标准简体中文字符集；
        3. utf-8：可以解决多种语言文本显示问题，从而实现应用国际化和本地化。
    10. Content-Type：POST请求中的数据类型；
        1. Text/XML; charset=gb2312 --&gt; 请求体中包含的是纯文件的XML类型的数据，
        字符编码是gb2312；
        2. application/x-www-form-urlencoded --&gt; 表单数据会按照 n1=v1&amp;n2=v2
        的形式进行编码，存储在请求体中。
3. 请求体：与请求头隔一个空行，存储提交的数据/参数。
</code></pre><h3 id="HTTP响应"><a href="#HTTP响应" class="headerlink" title="HTTP响应"></a>HTTP响应</h3><pre><code>响应的格式：状态行、响应头、空行、响应体
    HTTP/1.1 200 OK
    Server: Tengine
    Connection: keep-alive
    Date: Wed, 30 Nov 2016 07:58:21 GMT
    Cache-Control: no-cache
    Content-Type: text/html;charset=UTF-8
    Keep-Alive: timeout=20
    Vary: Accept-Encoding
    Pragma: no-cache
    X-NWS-LOG-UUID: bd27210a-24e5-4740-8f6c-25dbafa9c395
    Content-Length: 180945

    &lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; ....
1. Cache-Control: must-revalidate, no-cache, private
    1. Server不希望client缓存资源，在下次请求资源时，必须要重新请求Server，不能从
    缓存副本中获取资源；
    2. 当请求头中包含Cache-Control: max-age=0，明确表示不会缓存Server资源时，
    响应头中的Cache-Control通常为no-cache；
    3. 当请求头中没有Cache-Control时，Server往往会根据不同的资源执行不同的缓存策略，
    比如说oschina在缓存图片资源的策略就是Cache-Control：max-age=86400，即在86400s
    的时间内，client可以直接从缓存副本中读取资源，不需要再请求Server；
2. Connection: keep-alive --&gt; 告诉client，Server的TCP也是一个长链接；
3. Content-Encoding：响应资源所采用的编码格式，client应采用该编码进行解码；
4. Content-Type: text/html;charset=UTF-8 --&gt; 响应资源文件的类型及字符编码
    1. client通过utf-8对资源进行解码，然后对资源进行html解析；
    2. 如果网站乱码，往往是Server没有返回正确的编码。
5. Date：Server发送资源时的Server时间，GMT是格林尼治所在地的标准时间；
    HTTP协议的发送时间都是GMT，主要解决不同时区在互相请求资源时的时间混乱问题；
6. Expires: Sun, 1 Jan 2000 01:00:00 GMT --&gt; 也跟缓存有关，考虑到client和Server
    的时间不一定相同，Expires不如Cache-Control准确。
7. Pragma: no-cache --&gt; 与Cache-Control等同；
8. Server: Tengine/1.4.6 --&gt; 服务器和版本；
9. Transfer-Encoding: chunked --&gt; 告诉client，Server是分块发送资源的；
    1. 一般分块发送的资源都是Server动态生成的，再发送时还不确定资源的大小；
    2. 每一块都是独立的，都能标识自己的长度，当client读到长度为0的块时，则传输完毕。
10. Vary: Accept-Encoding --&gt; 告诉代理服务器缓存两种版本的资源：压缩和非压缩；
    因为现代浏览器都支持压缩，这个字段的用处并不大。
</code></pre><h4 id="响应状态码"><a href="#响应状态码" class="headerlink" title="响应状态码"></a>响应状态码</h4><pre><code>响应状态码：由3位数字组成，第一个数字表示响应的类别；
1. 100~199：Server成功接收部分请求，要求client继续提交其余请求才能完成整个处理过程；
2. 200~299：Server成功接收请求并已完成整个处理过程，常用200 OK 请求成功；
3. 300~399：为完成请求，client需要进一步细化请求，如：请求的资源已经移动一个新地址，
    常用302(所请求的页面已经临时转移至新的url)、307和304(使用缓存资源)；
4. 400~499：client的请求有错误；
    常用404(服务器找不到请求的页面)、403(服务器拒绝访问，权限不够)；
5. 500~599：Server出现错误，常用500(请求未完成，Server遇到不可预知的情况)。
</code></pre><h2 id="urllib2"><a href="#urllib2" class="headerlink" title="urllib2"></a>urllib2</h2><pre><code>urllib2是python2.7自带的模块，是很多网络爬虫的基础库，python3改名为urllib.request；
urllib2默认只支持HTTP/HTTPS的GET和POST；
1. 所谓的网页爬取，就是把URL地址中指定的网络资源从网络流中读取出来，保存到本地；
2. urllib2爬取百度首页
    1. res = urllib2.urlopen(&quot;http://www.baidu.com/&quot;)
    2. html = res.read() --&gt; 读取网络流中的资源；
    3. 如果中文乱码，可以使用html.decode(&apos;gbk&apos;)解码。
3. 对于缺省的请求头，urllib2会自动添加，但并不是模拟浏览器的header；
    1. 默认的User-Agent: Python-urllib/sys.version[0:3]
    2. import sys --&gt; sys.version[0:3] --&gt; 获取python的版本号
4. urllib2.Request()：构建请求头，模拟真实的client
    1. ua_headers = {&apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows......&apos;}
    2. request = urllib2.Request(&apos;http://www.baidu.com/&apos;, headers=ua_headers)
    3. res = urllib2.urlopen(request) --&gt; res.read()
    4. Request(url, data=None, headers={})：data是url提交的数据，如post的提交，
    同时HTTP请求将从GET改为POST。
    5. res.getcode() --&gt; HTTP响应码；
    6. res.geturl() --&gt; 实际响应数据的URL，防止重定向问题；
    7. res.info() --&gt; 响应的HTTP报文头。
5. User-Agent：用于决定用户的浏览器，为了获取更好的HTML页面效果；
    1. 除了Opera，其他浏览器都在间接或直接在Firefox的内核上披了一层外衣；
    2. Google:Chrome(like webkit) -&gt; Apple:Webkit(like KHTML) -&gt; Linux:KHTML
    (like Gecko) -&gt; Mozilla:Firefox(Gecko)，IE:Trident，Opera:Presto
    3. 构建一个User-Agent的列表，列表元素是浏览器真实的User-Agent信息：
    ua_list = [&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...&apos;, ......]
    4. import random --&gt; ua = random.choice(ua_list) --&gt; 随机选择一个元素；
    5. request.add_header(&apos;User-Agent&apos;, ua) --&gt; 动态添加请求头User-Agent；
    6. request.get_header(&apos;User-agent&apos;)：获取指定的请求头(注：只有首字母大写)；
6. URL的中文编码：import urllib
    1. URL包含中文在时，浏览器发起请求时会自动编码，比如北京：%E5%8C%97%E4%BA%AC
    每3个作为一组，表示一个中文；空格会被编码成&quot;+&quot;；
    2. urllib.urlencode(dict) --&gt; 编码的结果：&quot;key1=value1&amp;key2=value2&quot;
    3. 解码：urllib.unquote(&quot;wd=%E5%8C%97%E4%BA%AC&quot;) --&gt; wd=北京
    4. 一般HTTP请求提交数据，需要编码成URL编码格式，然后作为url的一部分，或者作为
    参数传到Request对象中。
7. urllib、urllib2：都是接受URL请求的相关模块，最显著的不同在于：
    1. urllib只可以接受URL，不能创建设置了headers的Request的实例对象；
    2. urllib可以用于URL的编码与解码：urlencode(dict)，unquote(str)
</code></pre><h3 id="GET与POST"><a href="#GET与POST" class="headerlink" title="GET与POST"></a>GET与POST</h3><pre><code>1. GET请求的参数拼接在URL上，比如百度贴吧的必要参数：kw、pn
    1. page = int(raw_input(&apos;请输入页码: &apos;))，pn = str((page-1)*50)
    2. params = urllib.urlencode({&apos;kw&apos;:&apos;平顶山学院&apos;, &apos;pn&apos;:pn})
    3. url = &apos;http://tieba.baidu.com/f?&apos; + params
2. POST的请求参数在请求体中，参数必须与爬取网站提交的参数完全一致；
    1. data = urllib.urlencode({&apos;k1&apos;:&apos;v1&apos;, &apos;k2&apos;:&apos;v2&apos;})
    2. request = urllib2.Request(url, data=data, headers)
    3. url并不是浏览器地址栏显示的，而是通过抓包工具获取的、表单提交的URL。
3. 在headers中加入client保存的Cookie，可以模拟用户的登录，爬取登录后才展示的数据；
4. headers中不要添加Accept-Encoding: gzip，否则爬取的数据会显示乱码，因为Server
   传输的是压缩数据；
5. 有时候POST也能在URL内看到数据，是因为Form表单没有指定method=&apos;post&apos;，默认get。
</code></pre><h3 id="AJAX"><a href="#AJAX" class="headerlink" title="AJAX"></a>AJAX</h3><pre><code>1. AJAX是动态加载数据的，所以做爬虫最需要关注的不是页面显示的信息，而是信息的来源；
2. AJAX方式加载的页面，数据来源一定是JSON，爬取到JSON，也就得到了数据；
3. 通过抓包工具，获取动态数据的URL及其参数，对URL进行POST/GET获取数据。
</code></pre><h3 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h3><pre><code>1. HTTPS请求需要通过SSL证书验证，如果网站的SSL证书是经过CA认证的，则能正常访问；
    1. 如果SSL证书验证不通过，浏览器会警告用户证书不受信任，如12306网站；
    2. urllib2在爬取&apos;https://www.12306.cn/mormhweb/&apos;时，会报出SSLError。
2. import ssl：SSL处理模块
    1. context = ssl._create_unverified_context() --&gt; 忽略未经允许的SSL证书
    2. response = urllib2.urlopen(request, context = context)
3. 除了电子交易等对安全要求比较高的网站必须使用HTTPS请求之外，一般支持HTTPS请求的URL，
   都支持HTTP请求，所以爬取的URL使用HTTP即可。
</code></pre><h2 id="Handler与Opener"><a href="#Handler与Opener" class="headerlink" title="Handler与Opener"></a>Handler与Opener</h2><pre><code>urllib2.urlopen()的实现过程：
    1. 默认创建的Handler处理器是HTTPSHandler，build_opener(handler)构建Opener实例；
    2. 由Opener的open()发送请求。
1. urllib2提供了很多Handler处理器，比如：使用HTTPHandler，自定义Opener
    handler = urllib2.HTTPHandler()
    opener = urllib2.build_opener(handler)
    request = urllib2.Request(&apos;http://www.baidu.com/&apos;)
    html = opener.open(request).read()
2. build_opener(handler1, handler2, ...)：可以同时添加多个处理器；
3. opener.addheaders = [(&apos;k1&apos;,&apos;v1&apos;), (&apos;k2&apos;,&apos;v2&apos;), ...]：也能为Opener添加请求头；
4. Handler支持调试：Handler(debuglevel=1)，会打印收包和发包的报头信息；
5. 提升自定义Opener为全局的：urllib2.install_opener(opener)，之后所有的urlopen()
   都将使用自定义Opener发送请求。
</code></pre><h3 id="ProxyHandler"><a href="#ProxyHandler" class="headerlink" title="ProxyHandler"></a>ProxyHandler</h3><pre><code>很多网站会检测某段时间内同一个IP的访问次数(流量统计、系统日志等)，禁止访问次数异常的IP；
所以，设置一些代理服务器，每隔一段时间换一个代理，即便IP被禁止，依然可以更换IP继续爬取。
1. ProxyHandler：代理处理器，使用代理IP，通常是最好用的爬虫/反爬虫机制；
2. ProxyHandler({&apos;代理类型&apos;: &apos;代理服务器的Ip:Port&apos;})：如果是空字典，表示不使用代理；
    1. http_proxy = ProxyHandler({&apos;http&apos;: &apos;124.88.67.54:80&apos;})
    2. 主机和代理服务器支持的编码可能不一致，而资源服务器是以代理服务器的编码为准，
    所以本机接收到代理服务器转发的数据之后，需要按照代理服务器的编码进行decode()解码。
3. 私密代理需要账号密码授权：ProxyHandler({&apos;代理类型&apos;: &apos;用户名:密码@Ip:Port&apos;})
    1. 用户名/密码错误，会报HTTP Error 407: Proxy Authentication Required
    2. 代理信息通常不会明文写在代码中，比如放在系统环境变量的配置文件中：
        proxyuser=&quot;用户名&quot;
        export proxyuser
        1. 执行命令：source 文件名 --&gt; 让新的配置信息生效
        2. import os --&gt; 用于操作系统相关的模块
        3. name = os.environ.get(&apos;proxyuser&apos;)
</code></pre><h3 id="授权验证处理器"><a href="#授权验证处理器" class="headerlink" title="授权验证处理器"></a>授权验证处理器</h3><pre><code>HTTPPasswordMgrWithDefaultRealm：密码管理对象，用于保存HTTP请求相关的用户名/密码；
主要应用：
    1. 私密代理授权验证的用户名和密码，对应处理器：ProxyBasicAuthHandler
    2. 验证Web Client的用户名和密码，对应处理器：HTTPBasicAuthHandler
1. ProxyBasicAuthHandler：可以处理代理身份验证的处理器，ProxyHandler的升级；
    1. 构建密码管理对象：mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
    2. 添加账户信息：mgr.add_password(None, &apos;代理服务器Ip:Port&apos;, &apos;用户名&apos;, &apos;密码&apos;)
    第一个参数是与远程服务器相关的域信息，一般为None；
    3. 构建处理身份验证的代理处理器：handler = urllib2.ProxyBasicAuthHandler(mgr)
    4. 因为这种方式比较复杂，通常还是直接使用ProxyHandler()实现私密验证。
2. HTTPBasicAuthHandler
    1. 有些WebServer访问时，需要进行用户身份验证，爬虫直接访问时会报HTTP 401
    2. 构建密码管理对象：mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
    3. 添加账户信息：mgr.add_password(None, &apos;服务器地址&apos;, &apos;用户名&apos;, &apos;密码&apos;)
    4. 构建WebClient授权验证的处理器：handler = urllib2.HTTPBasicAuthHandler(mgr)
</code></pre><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/10/01/Django/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/01/Django/" itemprop="url">Django</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-01T00:00:00+08:00">
                2017-10-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="虚拟环境"><a href="#虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境</h2><pre><code>安装搭建虚拟环境的工具：pip install virtualenv，然后做一些必要的配置；
1. 创建/删除一个虚拟环境：mkvirtualenv/rmvirtualenv 虚拟环境名
2. 进入一个虚拟环境：workon 虚拟环境名
3. 退出当前的虚拟环境：deactivate
4. 查看当前虚拟环境中已经安装的包：pip list，pip freeze
</code></pre><h2 id="django"><a href="#django" class="headerlink" title="django"></a>django</h2><pre><code>安装django并指定版本：pip install django==1.8.2，会自动删除旧版本
1. 查看django版本：python shell --&gt; import django --&gt; django.get_version()
2. 创建项目：django-admin startproject 项目名
   默认生成一个与项目同名的应用，用于项目的配置：
    1. manage.py：一个命令行工具，可以用多种方式对Django项目进行交互；
    2. settings.py：项目的配置文件； urls.py：项目的URL声明；
    3. wsgi.py：项目与WSGI兼容的Web服务器入口；
    4. django默认使用SQLite数据库，同时支持mysql、oracle
3. 一个项目包含多个应用，创建应用：python manage.py startapp 应用名
    1. 在settings.py中注册模型：INSTALLED_APPS = ( ... , &apos;模型名&apos;)
    2. 在模型/models.py中创建model，用于生成数据库；
    3. 数据库的迁移：python manage.py makemigrations --&gt; ... migrate
    4. 进入测试环境：python manage.py shell
4. 开启服务器：python manage.py runserver ip:port
    1. ip默认localhost/127.0.0.1，port默认8000
    2. 这是一个纯Python编写的轻量级web服务器，仅在开发阶段使用；
    3. 修改文件不需要重启服务器，增删文件则需要重启服务器。
5. 站点管理
    1. 站点分为：内容发布和公共访问，内容发布的部分负责添加、修改、删除内容；
    2. 创建管理员用户：python manage.py craetesuperuser
    3. 启动服务器，访问站点：http://127.0.0.1:8000/admin
    4. 管理站点的应用：项目settings.py中的
    INSTALLED_APPS = (&apos;django.contrib.admin&apos;, ...)
6. 使用MySql数据库
    1. 在虚拟环境中安装MySql包：pip install mysql-python
    2. 登录MySql创建数据库：create database test2 charset=utf8;
    3. 在项目settings.py配置MySql：
    DATABASES = { &apos;default&apos;: { &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;,
    &apos;NAME&apos;: &apos;test2&apos;, &apos;USER&apos;: &apos;用户名&apos;, &apos;PASSWORD&apos;: &apos;密码&apos;,
    &apos;HOST&apos;: &apos;数据库服务器ip，本地可用localhost&apos;, &apos;PORT&apos;: &apos;默认3306&apos; } }
7. settings.py修改测试模式为发布模式：
    1. DEBUG = False
    2. ALLOWED_HOSTS = [ &apos;*&apos;, ]：设置允许访问的主机，* 表示所有主机；
</code></pre><h2 id="状态保持"><a href="#状态保持" class="headerlink" title="状态保持"></a>状态保持</h2><pre><code>1. HTTP协议是无状态的，每一次请求都是新的，不会记录之前的通信状态；
2. 客户端与服务器端的一次通信，就是一次会话；
3. 实在状态保持的方式：在客户端/服务器端存储与会话有关的数据；
4. 存储方式：cookie、session，会话一般指session对象；
5. 状态保持的目的是在一段时间内跟踪请求者的状态，实现跨页面访问当前请求者的数据；
注意：但不同的请求者之间不会共享这个数据，该数据与请求者一一对应。
</code></pre><h3 id="session"><a href="#session" class="headerlink" title="session"></a>session</h3><pre><code>session：服务器端记录客户端状态的一种机制，相应地会增加服务器端的存储压力；
1. session是cookie的一种，使用方式类似，都是键值对形式；
2. cookie保存在客户端浏览器，不能存储敏感信息，而session保存在服务器，数据更安全，
   所以使用session实现状态保持；
3. session依赖于cookie，每个session在存储时，都有一个session_id作为唯一标识，
   cookie中存储有session_id，用于区分不同请求者的session.
</code></pre><h3 id="django与session"><a href="#django与session" class="headerlink" title="django与session"></a>django与session</h3><pre><code>1. django默认启用session，在settings.py中：
    1. INSTALLED_APPS：django.contrib.sessions
    2. MIDDLEWARE_CLASSES：
    django.contrib.sessions.middleware.SessionMiddleware
    3. 删除这两个元素，即可禁止会话session，可节省一些性能；
    4. session默认两个星期之后过期。
2. django默认将session存储在数据库中，所以使用session之前必须做数据库的迁移；
3. 在settings.py中设置session的存储方式：
    1. 默认方式：SESSION_ENGINE=&apos;django.contrib.sessions.backends.db&apos;
    2. 基于缓存：存储在内存中，django.contrib.sessions.backends.cache
    3. 同时使用缓存和数据库：优先从本地缓存中读取
    SESSION_ENGINE=&apos;django.contrib.sessions.backends.cached_db&apos;
4. 会话还支持文件、纯cookie、Memcached、Redis等方式存储，以Redis为例：
    1. 在当前虚拟环境下安装Redis：pip install django-redis-sessions
    2. 配置settings.py：
        SESSION_ENGINE = &apos;redis_sessions.session&apos;
        SESSION_REDIS_HOST = &apos;localhost&apos;
        SESSION_REDIS_PORT = 6379
        SESSION_REDIS_DB = 0
        SESSION_REDIS_PASSWORD = &apos;&apos;
        SESSION_REDIS_PREFIX = &apos;session&apos;
    3. 启动Redis：sudo redis-server /etc/redis/redis.conf
</code></pre><h2 id="DTL"><a href="#DTL" class="headerlink" title="DTL"></a>DTL</h2><pre><code>1. DTL：Django模板语言，定义在django.template包中，在HTML中使用；
    1. 变量语法：{{ 变量 }}
    2. 执行Python代码：{% 代码块 %}
    3. 过滤器：{{ 变量|过滤器 }}
    4. {\# 单行注释 \#}，{% comment %} 多行注释 {% endcomment %}
2. HTML转义：视图在向HTML中传递包含HTML标签的字符串时，Django会对标签自动转义；
    1. HTML标签原样输出、而不解释执行，是为了防止可能存在的攻击代码，如JS脚本；
    2. &lt; 转换为 &amp;lt，&gt; 转换为 &amp;gt，&apos; --&gt; &amp;#39，&quot; --&gt; &amp;quot，&amp; --&gt; &amp;amp；
    3. 转义的过滤器：escape，{{ t1|escape }}，Django默认自动转义，默认省略；
    4. 关闭转义的过滤器：safe，{{ t1|safe }}
    5. 关闭代码块的转义：{% autoescape off %} {{ t1 }} {% endautoescape %}
    6. base模板中关闭自动转义，其child模板也是关闭的。
</code></pre><h2 id="反向解析"><a href="#反向解析" class="headerlink" title="反向解析"></a>反向解析</h2><pre><code>域名：http://127.0.0.1:9000
&lt;a&gt;的href、&lt;form&gt;的action、&lt;img/&gt;的src在引用同域名的URL时，如href=&apos;/a/b/&apos;，
其中，第一个&apos;/&apos;表示项目的根目录，即引用的地址是域名+&apos;/a/b/&apos;：
http://127.0.0.1:9000/a/b/
而href=&apos;a/b/&apos;则表示当前目录，即当前地址+&apos;a/b/&apos;，假设当前地址为：
http://127.0.0.1:9000/m/n/
则引用地址为：http://127.0.0.1:9000/m/n/a/b/

反向解析：解除这种硬编码的形式，通过include()的namespace和url()的name动态生成URL。
1. 配置应用的urls.py：url(r&apos;^&apos;, include(&apos;booktest.urls&apos;, namespace=&apos;booktest&apos;))
2. booktest应用的urls.py：url(&apos;^$&apos;, views.index, name=&apos;index&apos;)
3. 使用反向解析策略：&lt;a href=&quot;{% url 'booktest:index' %}&quot;&gt;
4. 反向解析避免了硬编码，不再受限于项目配置应用url(r&apos;^&apos;, ...)中的正则变更。
</code></pre><h2 id="CSRF"><a href="#CSRF" class="headerlink" title="CSRF"></a>CSRF</h2><pre><code>CSRF：Cross Site Request Forgery，跨站请求伪造
1. 某些恶意网站上包含链接、表单或JS，它们利用登录过的用户在浏览器中的认证信息，试图在你的
   网站上完成某些操作，即跨站攻击；
2. django默认开启了CSRF防御，在配置应用的settings.py中，启用中间件：
    MIDDLEWARE_CLASSES = (&apos;django.middleware.csrf.CsrfViewMiddleware&apos;, )
3. 对于post请求的表单，必须加入CSRF验证，才能提交成功：
    &lt;form method=&apos;POST&apos;&gt; {% csrf_token %} ... &lt;/form&gt;
4. {% csrf_token %}其实是一个隐藏域：&lt;input type=&apos;hidden&apos; ... /&gt;
    在提交时，请求头中会携带一个cookie信息，用于验证身份；
5. 验证码也是有效防御CSRF的一种方式，原理：随机生成的验证码存储在session中，提交表单时，
   比较用户填写的验证码是否与session中的一致。
</code></pre><h2 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h2><pre><code>中间件：一个轻量级、底层的插件系统，可以介入Django的请求/响应处理过程，修改输入/输出。
1. 项目配置应用的settings.py中，MIDDLEWARE_CLASSES元组中元素都是激活的中间件；
2. 中间件的技术思想是AOP，面向切面编程，Django处理一个网络请求的过程：
    接收请求--A--&gt;匹配URL--B--&gt;查找视图View--C--&gt;对应模板Template--D--&gt;响应
3. 对于某些特殊需求，可能需要干涉网络请求的过程，从而不得不修改Django的源代码，为了应对
   这种需求，Django提供了中间件，可以干涉A、B、C、D四个环节，从而避免开发者修改源代码；
4. 中间件的本质也就是一个Python类，可以定义的方法包括：
    1. _init_：无需任何参数，服务器响应第一个请求时响应一次，用于确定是否启用中间件；
    2. process_request(request)：对应A环节，返回None/HttpResponse对象；
    3. process_view(request, view_func, view_args, view_kwargs)：对应B环节，
    返回None/HttpResponse对象；
    4. process_template_response(request, response)：对应C环节，返回实现了
    render()的响应对象；
    5. process_response(request, response)：对应D环节，返回HttpResponse对象；
    6. process_exception(request, response, exception)：当视图抛出异常时调用，
    返回一个HttpResponse对象，然后响应给浏览器；404是匹配URL的错误，不会调用。
    7. 自定义的中间件(Python类)也必须在MIDDLEWARE_CLASSES中注册，才会启用。
5. 使用中间件，可以干扰整个处理过程，每次请求中都会执行中间件的方法。
</code></pre><h2 id="静态文件管理"><a href="#静态文件管理" class="headerlink" title="静态文件管理"></a>静态文件管理</h2><pre><code>项目中的CSS、JS、图片都是静态文件，静态文件的处理并不需要经过Django，可以直接请求。
1. 为了便于迁移，在项目根目录下创建static文件夹，用于存放静态文件；
2. 项目的配置应用settings.py中：
    1. STATIC_URL = &apos;/static/&apos; --&gt; 静态文件的逻辑地址，用于伪装静态文件的真实目录；
    2. STATICFILES_DIRS = [ os.path.join(BASE_DIR, &apos;static&apos;), ] --&gt; 物理地址；
3. 在模板中使用一个静态文件：/static/myapp/logo.jpg
    1. 这种硬编码的形式，一旦STATIC_URL修改了，该地址也要修改；
    2. static编码：{% load static from staticfiles %}
    &lt;img src=&quot;{ % static &apos;myapp/logo.jpg&apos; %}&quot; alt=&quot;My image&quot;/&gt;
4. 对于上传的静态文件，则在static目录下创建media文件夹，settings.py中配置：
    MEDIA_ROOT = os.path.join(BASE_DIR, &apos;static/media&apos;)
</code></pre><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><pre><code>Django自带一个健壮的缓存系统来保存动态页面，避免对于每次请求都重新计算；
Django可以控制缓存粒度：缓存特定视图的输出、仅仅缓存难以生产的部分数据、缓存整个网站；
1. 缓存配置
    1. 缓存可以设置在数据库中、文件系统、内存中；
    2. 项目的配置应用settings.py：
    CACHES = {
        &apos;default&apos;: {
            &apos;BACKEND&apos;: &apos;django.core.cache.backends.locmem.LocMemCache&apos;,
            &apos;TIMEOUT&apos;: 60,
        }
    }
    BACKEND：设置缓存的存储位置；
    TIMEOUT：缓存的默认过期时间(s)，默认是300秒；None表示永不过期，0表示立即失效。
2. 启用Redis缓存：
    1. 安装包：pip install django-redis-cache，默认使用编号为1的数据库；
    2. 配置：
    &apos;BACKEND&apos;: &apos;redis_cache.cache.RedisCache&apos;,
    &apos;LOCATION&apos;: &apos;localhost:6379&apos;,
3. 缓存单个视图View
    1. from django.views.decorators.cache import cache_page
    2. @cache_page(timeout)：timeout表示过期时间，单位是秒；
    @cache_page(60 * 15)
    def index(request):
        pass
    3. 15分钟内重复访问index视图，数据都是从缓存中获取的，不会重复执行index()；
    4. 如果多个URL指向同一个视图，每个URL会分别缓存该视图。
4. 模板片段缓存：缓存模板中一块数据
    1. {% load cache %}
    2. {% cache 300 hello %} 被缓存的数据 {% endcache %}
    3. 500表示缓存时间(s)，hello表示缓存片段的名称。
5. 缓存视图内的某些数据
    1. from django.core.cache import cache
    2. 设置/获取：cache.set(key, value, timeout)，cache.get(key)
    3. 删除/清空：cache.delete(key)，cache.clear()
</code></pre><h2 id="事物"><a href="#事物" class="headerlink" title="事物"></a>事物</h2><pre><code>视图view在操作数据库时，如果不满足某种条件，或者发生异常，希望回滚到指定的代码位置；
from django.db import transaction
@transaction.atomic()
def handle(request):
    tran_id = transaction.savepoint() --&gt; 埋点
    try:
        ......
    except Exception as e:
        transaction.savepoint_rollback(tran_id) --&gt; 回滚到埋点处
</code></pre><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><pre><code>处理三个方面：uwsgi、nginx、静态文件static
1. 配置服务器上的python虚拟环境，安装所需要的包，用ftp把项目上传到服务器的某个目录；
2. 更改项目的setting.py文件：
    1. DEBUG = False
    2. ALLOW_HOSTS=[&apos;*&apos;, ] --&gt; 表示允许任何Ip的终端访问服务器
3. python manage.py runserver：启动服务器，运行正常，但是静态文件无法加载。
</code></pre><h3 id="WSGI"><a href="#WSGI" class="headerlink" title="WSGI"></a>WSGI</h3><pre><code>WSGI：生产环境使用，Web服务器网关接口，Python Web Server Gateway Interface
1. python manage.py runserver：只是一个适合开发阶段使用的服务器，不适合生产环境；
2. WSGI是Python应用/框架与Web服务器之间的一种接口，Django项目默认遵守WSGI协议，
   只要是实现了WSGI的产品，就可以运行Python代码；
3. WSGI没有官方的实现，因为WSGI更像一个协议，只要遵守这些协议，WSGI应用就可以在任何
   服务器上运行。
4. django命令创建项目时会生成一个简单的wsgi.py文件，配置了项目的运行环境；
   wsgi.py确定了settings、application对象：
    1. 在Python模块中使用application对象与应用服务器交互；
    2. Django需要导入settings模块，它是定义应用的地方。
注：此处所指的服务器其实就是一个软件，可以监听网卡端口、遵从网络层传输协议、收发Http协议
    级别的数据。
</code></pre><h3 id="uWSGI"><a href="#uWSGI" class="headerlink" title="uWSGI"></a>uWSGI</h3><pre><code>1. uWSGI实现了WSGI的所有接口，是一个快速、自我修复、开发人员和系统管理员友好的服务器；
2. uWSGI代码完全用C编写，可以监听网卡的某个端口，获取请求报文，交给python代码处理；
3. 安装：pip install uwsgi，在项目的根目录下新建uwsgi.ini，用于配置uWSGI
    [uwsgi]
    socket=外网Ip:端口 --&gt; 使用nginx连接时，只能使用socket协议
    http=外网ip:端口 --&gt; 直接做web服务器，则使用Http协议，与socket二选一
    chdir=项目根目录，绝对路径
    wsgi-file=项目中wsgi.py文件的目录，相对于项目根目录
    processes=4 --&gt; 启用n个进程运行uWSGI服务器
    threads=2 --&gt; 每个进程启用n个线程运行uWSGI服务器，进程和线程的数量与硬件配置有关
    master=True --&gt; 作为主机运行
    pidfile=uwsgi.pid --&gt; 记录uWSGI服务的pid，便于关闭服务
    daemonize=uwsgi.log --&gt; 指定记录日志的文件
4. 启动：uwsgi --ini uwsgi.ini    停止/重启：uwsgi --stop/reload uwsgi.pid
5. 使用http协议查看网站运行情况，运行正常，但是静态文件无法加载。
</code></pre><h3 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h3><pre><code>1. nginx的作用：
    1. 负载均衡：多台服务器轮流处理请求；
    2. 反向代理：隐藏真实服务器。
2. 实现架构：客户端请求nginx --&gt; nginx请求uwsgi --&gt; 运行框架下的python代码；
3. 安装：sudo apt-get install nginx
    1. 主程序目录：/usr/sbin/nginx    配置文件目录：/etc/nginx
    2. 存放静态文件的目录：/usr/share/nginx    日志目录：/var/log/nginx
    3. sudo nginx：启动；    sudo nginx -v：查看版本；
    4. 停止/重启：sudo nginx -s stop/reload
4. 配置：/etc/nginx/nginx.conf --&gt; http节点：include /etc/nginx/sites-enabled/*
    1. sites-enabled目录下有文件default，可配置多个server节点，对应多个服务器；
    server {
        listen 192.168.233.128:80 default_server; --&gt; nginx监听的Ip和端口；
        location / {    --&gt; 配置转发的uwsgi
            include uwsgi_params; --&gt; 将所有的参数转给uwsgi
            uwsgi_pass 192.168.233.128:8989; --&gt; uwsgi.ini中配置的Ip和端口
        }
    }
    2. 配置uswgi.ini，禁用http：socket=192.168.233.128:8989
    3. 重启uwsgi、nginx，访问http://192.168.233.128/，80是http的默认端口。
</code></pre><h3 id="静态文件"><a href="#静态文件" class="headerlink" title="静态文件"></a>静态文件</h3><pre><code>对于静态文件，nginx可以直接返回给客户端，不需要再转到uwsgi；
1. 在server节点下配置静态文件路径：
    server {
        ...
        location /static {
            alias /var/www/项目名/static/;
        }
    }
2. 在服务器的/var/www目录下创建一个与项目同名的目录，如servtest
    1. 修改其权限：sudo chmod 777 /var/www/servtest
    2. 在servtest目录下创建static目录，用于存放静态文件；
    3. 配置项目的settings.py：STATIC_ROOT=&apos;/var/www/servtest/static/&apos;
    4. 收集所有静态文件到STATIC_ROOT指定的目录：python manage.py collectstatic
3. 重启uwsgi、nginx，即可访问到静态文件；
4. 同理，MEDIA_ROOT=&apos;/var/www/servtest/static/media&apos;
</code></pre><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/08/10/Redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/10/Redis/" itemprop="url">Redis</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-10T00:00:00+08:00">
                2017-08-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h2><pre><code>Redis是一种key-value型的NoSQL数据库，配置文件的所在路径：/etc/redis/redis.conf
1. redis.conf的说明：
    1. port 6379：默认端口为6379
    2. daemonize yes：表示以守护线程运行，不会再命令行阻塞，类似于服务；
    3. databases 16：默认16个数据库，编号为0-15，默认使用的是0号数据库；
    4. dbfilename dump.rdb：数据文件；
    5. dir /var/lib/redis：数据文件的存储路径，默认路径为./
2. 启动Redis
    1. 查看Redis是否启动：ps ajx|grep redis
</code></pre><p><img src="https://i.imgur.com/nVUC452.jpg" alt></p>
<pre><code>    2. 配置文件的方式启动
        1. redis-server命令直接启动Redis，会阻塞当前终端；
        2. 如果配置文件所在路径为/usr/local/redis/redis.conf，则拷贝到/etc/redis
        目录下：sudo cp /usr/local/redis/redis.conf /etc/redis/
        3. 指定配置文件启动：sudo redis-server /etc/redis/redis.conf
    3. sudo service redis start/stop/restart：后台启动/停止/重启Redis服务。
3. 连接Redis服务：redis-cli，默认连接本机的Redis
4. 切换数据库：select 编号，默认使用的是0号数据库。
</code></pre><h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><pre><code>Redis是key-value类型的数据，所以每个数据都是一个键-值对；
1. 键的类型为字符串；
2. 值的类型有5种：字符串string、哈希hash、列表list、集合set、有序集合zset
</code></pre><h3 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h3><pre><code>string是Redis最基本的类型，最大存储512MB的数据；
string类型是二进制安全的，即可以为任何数据，包括数字、图片、序列化对象等；
1. 设置
    1. set key value：设置键-值，比如set name &apos;python&apos;；
    2. SETEX key seconds value：设置键值及过期时间，以秒为单位，过期之后会被删除；
    3. 设置多个键-值：MSET key value key value ...
2. 获取
    1. GET key：根据键获取值，如果不存在，则返回nil；
    2. MGET key key ...：根据多个键获取多个值。
3. 运算
    1. 运算的前提：值必须是数字；
    2. INCR/DECR key：将key对应的value加/减1；
    3. INCRBY/DECRBY key number：对value加/减整数，number可以是正数/负数；
    4. 追加值：APPEND key value，相当于拼接字符串；
    5. STRLEN key：获取值的长度/字符个数。
</code></pre><h3 id="键操作"><a href="#键操作" class="headerlink" title="键操作"></a>键操作</h3><pre><code>1. KEYS pattern：查找键，参数pattern支持正则表达式，比如KEYS *，查找所有键；
2. EXISTS key key ...：判断某个/某些键是否存在，返回存在的个数，都不存在则返回0；
3. TYPE key：查看key对应的value的类型，虽然返回string，但并不一定代表的是字符串；
4. DEL key key ...：删除键-值；
5. EXPIRE key seconds：重新对键-值设置过期时间；
6. TTL key：查看有效时间，已过期/不存在的键-值返回-2，永久存在的键-值返回-1。
</code></pre><h3 id="hash操作"><a href="#hash操作" class="headerlink" title="hash操作"></a>hash操作</h3><pre><code>hash用于存储对象，对象的格式为键值对；
1. 设置
    1. 单个属性：HSET key field value，比如 HSET py name &apos;Mike&apos;
    2. 多个属性：HMSET key field value field value ...
    3. type key：hash
2. 获取
    1. 一个属性值：HGET key field
    2. 多个属性值：HMGET key field field ...
    3. 获取所有的属性和属性值：HGETALL key，比如 HGETALL py --&gt; &apos;name&apos;，&apos;Mike&apos;
    4. 获取所有属性：HKEYS key
    5. 获取所有属性值：HVALS key
    6. 获取属性的个数：HLEN key
3. 判断属性是否存在：HEXISTS key field，存在则返回1，不存在则返回0；
4. 删除属性及值：HDEL key field field ...
5. 获取属性值的长度：HSTRLEN key field
</code></pre><h3 id="list操作"><a href="#list操作" class="headerlink" title="list操作"></a>list操作</h3><pre><code>列表的元素类型为string，按照插入顺序排序，在列表的头部或尾部添加元素；
一个key对应一个列表，列表为空时，key也会被删除；
1. 设置
    1. 在头/尾部插入一个元素：LPUSH/RPUSH key value value ...
    插入多个元素时，其实也是一个个元素依次插入的，所以最后一元素会排列在头/尾部
    2. 在一个元素的前/后插入新元素：LINSERT key BEFORE/AFTER ref_value value
    3. LSET key index value：指定索引位置插入一个新元素；
        1. index是元素的索引，从 0 开始，索引不能越界；
        2. 索引可以是负数，-1表示列表的最后一个元素。
2. 获取
    1. LPOP/RPOP key：移除并返回列表key的第一个/最后一个元素，空列表则返回nil；
    2. LRANGE key start end：获取索引start到索引end的所有元素；
        1. start和end可以是任意大小，而不会角标越界；
        2. start和end可以是负数，-1表示最后一个元素。
3. LTRIM key start end：裁剪列表，只保留索引start到索引end的元素；
4. LLEN key：返回列表的长度；
5. LINDEX key index：返回索引index对应的元素。
</code></pre><h3 id="set操作"><a href="#set操作" class="headerlink" title="set操作"></a>set操作</h3><pre><code>set是无序集合，元素是string类型，元素具有唯一性，不重复；
1. 添加元素：SADD key member member ...
2. 获取元素：SMEMBERS key
3. SCARD key：返回元素个数；
4. SINTER key key ...：求集合的交集；
5. SDIFF key key ...：求某集合与其它集合的差集；
6. SUNION key key ...：求集合的并集；
7. SISMEMBER key member：判断元素member是否在集合中，存在则返回1，不存在则返回0
</code></pre><h3 id="zset操作"><a href="#zset操作" class="headerlink" title="zset操作"></a>zset操作</h3><pre><code>zset是有序集合，元素是string类型，元素具有唯一性，不重复；
每个元素都会关联一个double类型的score，表示权重，通过权重将元素从小到大排序；
元素的权重score是自定义的，也即可以指定元素的顺序，score可以相同；
1. 添加：ZADD key score member score member ...
2. ZRANGE key start end：返回指定范围内的元素；
3. ZCARD key：返回元素个数；
4. ZCOUNT key min max：返回score在min和max之间的元素个数；
5. ZSCORE key member：返回元素member对应的score，不存在则返回nil；
</code></pre><h2 id="发布订阅"><a href="#发布订阅" class="headerlink" title="发布订阅"></a>发布订阅</h2><pre><code>发布者不关心订阅者/接收者的类型，只是将消息发布到不同的频道，会自动推送给订阅者；
订阅者不需要主动请求/获取数据，只需要订阅频道，频道的消息内容就会被推送过来；
发布者和订阅者是解耦和的一种模式，使网络拓扑的扩展性更强、更加动态。
1. 消息的格式包含三个部分：
    1. 第一部分表示消息的类型：
        1. subscribe，表示订阅成功；
        2. unsubscribe，表示取消订阅成功；
        3. message，表示其它终端发布消息。
    2. 当第一部分为subscribe时，则第二部分表示频道，第三部分表示当前订阅频道的数量；
    3. 当第一部分为unsubscribe时，则第二部分表示频道，第三部分表示当前订阅的频道数，
       如果为0，则表示当前没有订阅任何频道；
    4. 当第一部分为message时，则第二部分表示来源频道的名称，第三部分表示消息的内容。
2. 订阅：SUBSCRIBE 频道名称 频道名称 ...
3. 取消订阅：UNSUBSCRIBE 频道名称 频道名称 ... 如果不加参数，则取消所有订阅；
4. 发布：PUBLISH 频道 消息
</code></pre><p><img src="https://i.imgur.com/vggtGkf.jpg" alt></p>
<h2 id="主从配置"><a href="#主从配置" class="headerlink" title="主从配置"></a>主从配置</h2><pre><code>一个主节点可以拥有多个从节点，一个从节点又可以拥有多个从节点，从而形成强大的多级服务器
集群架构；
比如：将Ip为192.168.1.10的机器作为主服务器，将Ip为192.168.1.11的机器作为从服务器
1. 修改主服务器的配置文件：bind 127.0.0.1 --&gt; bind 192.168.1.10
2. 设置从服务器的配置文件：
    1. bind 127.0.0.1 --&gt; bind 192.168.1.11
    2. 换行，再加上：slaveof 192.168.1.10 6379
3. 修改了配置文件之后，必须重启Redis服务；
4. redis-cli命令默认使用的Ip是127.0.0.1，修改了绑定的Ip之后，再次登录主/从服务器时，
   必须指定Ip：redis-cli -h Ip
5. 测试：在主服务器上操作数据库，可以在从服务器上获取到相同的数据。
</code></pre><h2 id="Redis与Python"><a href="#Redis与Python" class="headerlink" title="Redis与Python"></a>Redis与Python</h2><pre><code>1. 安装redis模块
    1. 联网安装：sudo pip3 install redis
    2. 源码安装：
        1. unzip redis-py-master.zip
        2. cd redis-py-master
        3. sudo python setup.py install
2. 导入redis模块：import redis
3. 连接Redis，获取客户端对象：r=redis.StrictRedis(host=&apos;Ip&apos;, port=6379)
4. Windows上的PyCharm编写连接Ubuntu上的Redis的代码时，Redis的配置文件中所绑定的Ip
   不能使用默认的127.0.0.1，而必须配置为Ubuntu的Ip，否则会连接失败。
</code></pre><h3 id="Python操作Redis的方式"><a href="#Python操作Redis的方式" class="headerlink" title="Python操作Redis的方式"></a>Python操作Redis的方式</h3><pre><code>1. 直接操作：读写方法会被立即执行；
    1. r.set(&apos;name&apos;, &apos;Hello Redis&apos;)：写入数据；
    2. r.get(&apos;name&apos;)：获取数据。
2. 管道操作：在内存中会维护读写操作，在调用管道的 execute() 之后，才会作用于数据库；
    1. pipe = r.pipeline()
    2. pipe.set(&apos;name&apos;, &apos;Hello Redis&apos;)：在管道中做写入操作；
    3. pipe.get(&apos;name&apos;)：在管道中做读取操作；
    4. pip.execute()：将管道中的所有读写操作一次性作用于数据库。
</code></pre><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/08/09/MongoDB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/09/MongoDB/" itemprop="url">MongoDB</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-09T00:00:00+08:00">
                2017-08-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="NoSQL简介"><a href="#NoSQL简介" class="headerlink" title="NoSQL简介"></a>NoSQL简介</h2><pre><code>NoSQL：Not Only SQL，非关系型数据库，不基于E-R模型，没有统一的结构，不用维护复杂的关系；
    1. NoSQL拥有内存级的数据读写，比物理磁盘级的读写速度更快；
    2. 高可扩展性，分布式计算，低成本，架构灵活，半结构化数据，但没有标准化，程序不直观；
NoSQL的分类：
    1. 列存储：Cassandra、Hypertable
    2. 文档存储：MongoDB、CouchaDB ...
       一般用类似JSON的格式存储，可以为某些字段建立索引，实现关系型数据库的某些功能；
    3. key-value存储：Redis、MemcacheDB、Berkeley DB... 通过key可以快速查询到value；
    4. 图存储：Neo4J、FlockDB
       图形关系的最佳存储，而使用传统的关系型数据库，则性能低下；
    5. 对象存储：db4o、Versant
    6. xml数据库：baseX、Berkeley DB XML
用户在访问一个Web应用时，查找数据的过程：应用 --&gt; NoSQL --&gt; 关系型数据库；
    1. 从关系型数据库中查到的数据，会先缓存到NoSQL中，并设置数据的过期时间，其他用户再次
    访问时，就可以直接从NoSQL中获取数据，提高查询效率，也减轻了关系型数据库的压力；
    2. 比如taobao的主页，每个用户访问的页面都是相同的，在第一次被访问后，就缓存到NoSQL中。
高并发的处理策略：分布式、集群、缓存
    1. 分布式：对于10个服务器，如果一个任务可以分成10个小任务，则每个服务器完成一个小任务；
    2. 集群：后台同时接收10个任务，每个服务器独立完成一个任务；
    3. 缓存：NoSQL数据库做缓存。
</code></pre><h2 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h2><pre><code>MongoDB：一个基于分布式文件存储的NoSQL数据库；
    1. 内存级的读写效率，在物理上以文件的形式存储数据，数据结构由键-值对组成；
    2. 由C++编写，稳定且性能高，为Web应用提供可扩展的高性能数据存储。
    3. 模式自由：可以不同结构的文档存储在同一个数据库；
    4. 面向集合的存储：适合存储JSON风格的文件形式；
    5. 完整的索引支持：对任何属性都可以索引；
    6. 复制和高可用性：支持服务器之间的数据复制，支持主-从模式及服务器之间的相互复制；
       复制的主要目的是提供冗余及自动故障转移。
    7. 自动分片：支持云级别的伸缩性，支持水平的数据库集群，可动态添加额外的机器。
1. MongoDB与MySQL的概念对比：
    1. database ---&gt; batabase：数据库，MongoDB和MySQL也都支持索引index；
    2. table ---&gt; collection：表 --&gt; 集合；
    3. row ---&gt; document：行 --&gt; 文档，比如 {&apos;name&apos;:&apos;Mike&apos;, &apos;gender&apos;:&apos;男&apos;}
       文档其实就是一个由键值对构成、BSON形式的对象，BSON是JSON的扩展；
    4. column ---&gt; field：列/字段 --&gt; 域/属性；
    5. primary key ---&gt; primary key：主键，MongoDB自动将_id字段设置为主键；
    6. MongoDB不维护复杂的关系，也就不支持表的连接查询。
2. 32位的MongoDB最大只能存储2G的数据，而64位的MongoDB则没有限制；
3. MongoDB也分为服务端mongod和客户端mongo；
    1. 服务端配置文件的目录为/etc/mongod.conf，默认Ip为127.0.0.1，默认端口为27017，
    默认数据库目录/data/db
        1. 显式启动：mongod，会显示启动过程，可以查看是否启动成功；
        2. 后台启动/重启/停止：sudo service mongod start/restart/stop；
        3. 后台启动之后，检查是否启动成功的命令：ps ajx|grep mongod
    2. mongod启动失败
        1. exception ... Data directory /data/db not found.
        解决：在根目录&apos;/&apos;下创建目录/data/db，并修改data的权限为777；
        2. failed to ... /tmp/mongodb ... not permitted.
        解决：1.chown root:root /tmp  2.chmod 777 /tmp
    3. 客户端启动连接：mongo，是一个shell脚本，同时也是一个JS的编辑器；
4. 图形界面的管理软件：robomongo
</code></pre><h2 id="操作MongoDB"><a href="#操作MongoDB" class="headerlink" title="操作MongoDB"></a>操作MongoDB</h2><h3 id="数据库操作"><a href="#数据库操作" class="headerlink" title="数据库操作"></a>数据库操作</h3><pre><code>1. db：查看当前数据库名，默认数据库是test；
2. db.stats()：查看当前数据库的信息；
3. show dbs：查看所有数据库；
4. use 数据库名：切换数据库，切换一个不存在的数据库，虽然物理上不存在，但是会在新建集合或
    插入数据时自动创建；
5. db.dropDatabase()：删除当前操作的数据库。
</code></pre><h3 id="集合操作"><a href="#集合操作" class="headerlink" title="集合操作"></a>集合操作</h3><pre><code>1. 创建集合：db.createCollection(集合名, options)
    1. options是可选参数，用于指定集合的配置，限制集合的大小，不指定则表示不设置上限；
    db.createCollection(&apos;sub&apos;, {capped:true, size:10})
    2. capped的默认值为false，表示不设置集合的上限大小；capped设置为true时，size用于
       指定集合的大小，单位是字节，一旦存储的文档达到上限，之前的数据会被覆盖。
2. 查看所有集合：show collections
3. 删除集合：db.集合名.drop()
</code></pre><h3 id="文档操作"><a href="#文档操作" class="headerlink" title="文档操作"></a>文档操作</h3><pre><code>1. 数据类型
    1. Object ID：每个文档都有一个属性_id，保证文档的唯一性，类似于MySQL中的主键；
        1. _id的类型是Object ID，由MongoDB自动维护，也可以显式设置，但不允许重复；
        2. Object ID是一个12字节的十六进制数：前4个字节是当前时间戳，3个字节的机器ID，
        MongoDB的服务进程ID占2个字节，最后3个字节是简单的增量值。
    2. String：字符串，必须设置为utf-8才有效；
    3. Boolean：存储一个布尔值，true/false；
    4. Integer：整数可以是32位/64位，取决于服务器；  Double：浮点数；
    5. Arrays：数据/列表，一个键对应多个值；
    6. Object：用于嵌入式的文档，即一个文档作为一个值；  Null：存储Null值；
    7. Timestamp：时间戳；  Date：存储当前日期/时间的UNIX时间。
2. 查看集合中的文档：db.集合名.find()
3. 插入文档：db.集合名.insert(document)
    1. db.stu.({name:&apos;Mike&apos;,gender:1})，如果操作的集合不存在，则自动创建；
    2. doc={name:&apos;DD&apos;}，doc.gender=0 --&gt; db.stu.insert(doc)
4. 更新文档：db.集合名.update({query}, {update}, {multi:true/false})
    1. query：查询条件，比如匹配包含键-值为name:&apos;Mike&apos;的文档，条件为{name:&apos;Mike&apos;}；
        如果不设置条件，则用 {} 作占位符；
    2. update：更新的内容；
    3. multi：可选，默认为false，表示只更新匹配的第一条文档，设置为true表示全部更新；
    4. update默认会对除了_id属性之外的所有属性覆盖更新，修改掉整个文档的结构：
</code></pre><p><img src="https://i.imgur.com/ugdmhbD.jpg" alt></p>
<pre><code>5. $set：只修改指定的属性，如果该属性不存在，则相当于为匹配的文档添加一个新的属性；
        而且，multi 必须和 $ 配合使用才有效，单独使用 multi 会报异常；
</code></pre><p><img src="https://i.imgur.com/9LNzoX8.jpg" alt></p>
<pre><code>5. 保存(添加/修改)：db.集合名.save(document)
    如果文档的_id已经存在，则相当于修改文档，如果不存在，则添加一个新的文档。
6. 删除：db.集合名.remove({query}, {justOne:false})
    1. query：删除的文档条件；
    2. justOne：可选，默认为false，表示删除所有匹配的文档，设置为true/1，只删除第一条；
    3. remove({}) 表示删除所有文档。
</code></pre><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><pre><code>1. db.集合名.find({条件文档})：查询匹配条件的所有文档；
2. db.集合名.findOne({条件文档})：只查询第一条匹配的文档；
3. find({条件文档}).pertty()：格式化显示文档；
4. 比较运算符
    1. 没有显式的等于运算符，默认就是等于判断；
    2. $lt：小于，$lte：小于或等于，$gt：大于，$gte：大于或等于，$ne：不等于；
    3. find({age:{$gt:18}})：查询年龄age&gt;18的文档。
5. 逻辑运算符
    1. 默认就是逻辑与，没有显式的逻辑与运算符；
    find({age:{$lt:20},gender:1})：查询年龄小于20，且性别为1的文档；
    2. $or：逻辑或，对应一个文档数组[{...},{...},{...}]
    find({$or:[{age:{$lt:20}},{gender:1}]})：年龄小于20，或性别为1的文档；
    3. 逻辑与和逻辑或同时使用：find({$or:[{age:{$lt:20}},{gender:1}],name:&apos;Mike&apos;})
        年龄小于20，或性别为1，且姓名为Mike的文档。
6. 范围运算符
    1. $in：在指定的数组中[x,y,z]；
    2. $nin：不在某个范围内；
    3. find.({age:{$in:[10,18,20]}})：年龄为10/18/20的文档。
7. 支持正则表达式
    1. /正则/，&amp;regex
    2. find({name:/^李/})，find({name:{$regex:&apos;^李&apos;}})：查询姓李的文档。
8. 自定义查询
    1. $where：JavaScript结合Mongo进行查询，使用JS定义查询的函数，功能强大；
    2. find({$where:function(){return this.age&gt;20}})：年龄age&gt;20的文档。
</code></pre><h3 id="高级查询"><a href="#高级查询" class="headerlink" title="高级查询"></a>高级查询</h3><pre><code>1. limit与skip
    1. db.集合名.find().limit(number)：显示number条文档，不指定number则显示全部；
    2. db.集合名.find().skip(number)：跳过number条文档，默认值为0；
    3. limit()和skip配合使用(不分先后)，才可以实现MySQL中的分页limit；
    4. find().skip(5).limit(4)：跳过5条文档，取第6条到第9条文档。
2. 投影
    1. 在返回查询的结果时，只希望显示文档的指定字段，而不显示整个文档；
    2. 投影文档是 find() 的第二个参数：find({},{属性名:1,...})，设置为1，表示显示；
       设置为0 或不设置，则不显示；但是，_id默认是显示的，需要手动设置为0 才会不显示。
3. 排序：sort()
    1. 对结果集排序：db.集合名.find().sort({属性:1,...})，1 升序，-1 降序；
    2. 比如 db.stu.sort({gender:-1,age:1})：先根据性别降序，再根据年龄升序；
    3. 结果集默认是根据_id属性排序。
4. 统计：count()
    db.集合名.find({条件文档}).count() 等效于 db.集合名.count({条件文档})
5. 消除重复：distinct()
    1. db.集合名.distinct(&apos;属性名&apos;,{条件文档})，也可以结合 find() 使用；
    2. 比如 distinct(&apos;gender&apos;,{age:{$gt:18}})：查找年龄age&gt;18的性别，并去重；
    3. 查询的结果集是一个数组/列表，元素是gender的属性值。
</code></pre><h2 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h2><pre><code>db.集合名.aggregate([{管道:{表达式}}])
1. 管道
    1. 在Unix和Linux中，管道一般用于将当前命令的输出结果，作为下一个命令的输入；
       比如 ps ajx | grep mongo：grep 从 ps ajx 得到的结果集中搜索 mongo
    2. 在MongoDB中，管道具有同样的作用，文档处理完毕后，通过管道进行下一次处理。
2. 常用的管道
    1. $group：对集合中的文档分组，可用于统计结果；
    2. $match：过滤数据，只输出匹配条件的文档；
    3. $project：投影，修改输入文档的结构，如重命名、增加、删除属性、创建计算结果...
    4. $sort：将输入文档排序后输出；
    5. $limit：限制聚合管道返回的文档数；
    6. $skip：跳过指定数量的文档，并返回剩下的文档；
    7. $unwind：将数组类型的属性进行拆分。
3. 表达式
    1. 表达式:&apos;$属性名&apos;
    2. 常用表达式
        1. $sum：计算总和，$sum:1 和 count() 都表示计数；
        2. $avg：计算平均数；
        3. $min/max：获取最小/最大值；
        5. $push：在结果文档中插入值到一个数组中；
        6. $first/last：根据资源文档的排序获取第一个/最后一个属性值。
</code></pre><h3 id="分组：-group"><a href="#分组：-group" class="headerlink" title="分组：$group"></a>分组：$group</h3><pre><code>1. _id 表示分组的依据，不能自定义，使用属性的格式：&apos;$属性名&apos;；
比如，统计男生女生的人数：
</code></pre><p><img src="https://i.imgur.com/R5ZPW3Q.jpg" alt></p>
<pre><code>$sum:1 表示计数，$sum:&apos;$属性名&apos; 则表示基于某个属性求和，比如对年龄求和：$sum:&apos;$age&apos;；
同理，$avg:&apos;$属性名&apos; 对某个属性求平均值，$last:&apos;$age&apos;获取本组中排序最后的一个年龄值。
2. 透视数据
$push:&apos;$age&apos; 将每一组年龄的属性值组成一个数组；
$push:&apos;$$ROOT&apos; 将每一组的整个文档组成一个数组；
</code></pre><p><img src="https://i.imgur.com/RCFAnAr.jpg" alt></p>
<pre><code>3. _id:null 则表示把集合分成一组，比如统计总人数和平均年龄：
</code></pre><p><img src="https://i.imgur.com/FOFObvH.jpg" alt></p>
<h3 id="过滤：-match"><a href="#过滤：-match" class="headerlink" title="过滤：$match"></a>过滤：$match</h3><pre><code>1. 支持MongoDB的标准查询操作
比如查询/过滤年龄大于20的文档：db.stu.aggregate([{$match:{age:{$gt:20}}}])
2. 对过滤后的文档进行聚合操作
比如，对过滤后的文档进行分组、统计：db.stu.aggregate([{$match:{age:{$gt:20}}},
{$group:{_id:&apos;$gender&apos;,count:{$sum:1}}}])
</code></pre><h3 id="投影：-project"><a href="#投影：-project" class="headerlink" title="投影：$project"></a>投影：$project</h3><pre><code>1. 与find()的投影功能相同
比如只输出属性name、age：db.stu.aggregate([{$project:{_id:0,name:1,age:1}}])
2. 对聚合后的文档做投影
比如只输出分组后的人数：aggregate([{$group:{_id:&apos;$gender&apos;,count:{$sum:1}}},
{$project:{_id:0,count:1}}])
</code></pre><h3 id="排序：-sort"><a href="#排序：-sort" class="headerlink" title="排序：$sort"></a>排序：$sort</h3><pre><code>1. 与sort()的功能相同
比如按年龄升序：db.stu.aggregate([{$sort:{age:1}}])
2. 对聚合后的文档做排序
比如对分组后的人数做降序：aggregate([{$group:{_id:&apos;$gender&apos;,count:{$sum:1}}},
{$sort:{count:-1}}])
</code></pre><h3 id="分页：-limit、-skip"><a href="#分页：-limit、-skip" class="headerlink" title="分页：$limit、$skip"></a>分页：$limit、$skip</h3><pre><code>在分页时，$skip必须在$limit的前面使用：aggregate([{$skip:2},{$limit:5}])
</code></pre><h3 id="拆分：-unwind"><a href="#拆分：-unwind" class="headerlink" title="拆分：$unwind"></a>拆分：$unwind</h3><pre><code>基于某一个数组类型的属性，将文档拆分成多个子文档，每个子文档包含该数组的一个元素；
1. db.集合名.aggregate([{$unwind:&apos;$属性名&apos;}])
</code></pre><p><img src="https://i.imgur.com/EgbuMyz.jpg" alt></p>
<pre><code>2. 如果拆分的属性是空数组、非数组类型、不存在、null，则拆分失败，数据丢失；
$unwind:{path:&apos;属性名&apos;,preserveNullAndEmptyArrays:true}：防止数据丢失；
</code></pre><p><img src="https://i.imgur.com/DYcOal2.jpg" alt></p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><pre><code>1. MongoDB也支持索引，以提升查询速度，索引的创建原则与MySQL的相同；
2. 查询性能分析：db.集合名.find({条件文档}).explain(&apos;executionStats&apos;)
    executionStats下的executionTimeMillis表示整体查询时间，单位是毫秒；
3. 创建索引
    1. 普通索引：db.集合名.ensureIndex({属性名:1})，1 升序，-1 降序；
    2. 唯一索引：ensureIndex({属性名:1},{unique:true})，属性值不能重复；
    3. 联合索引：ensureIndex({属性名:1,属性名:1})，基于多个属性，创建一个索引。
4. 查看集合中的所有索引：db.集合名：getIndexes()，同时会列出索引名称；
5. 删除索引
    1. 根据索引名称删除：db.集合名.dropIndex(&apos;索引名&apos;)
    2. 删除所有索引：db.集合名.dropIndexes()，_id是一个特殊的索引，不会被删除。
</code></pre><h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><pre><code>1. MongoDB采用角色-用户-数据库的安全管理方式，为了安全性，需要访问者提供用户名和密码；
2. 常用的系统角色：
    1. root：只在admin数据库中可以使用，超级权限/账号；
    2. Read：允许用户读取指定的数据库；
    3. readWrite：允许用户读写指定的数据库。
</code></pre><h3 id="超级管理用户"><a href="#超级管理用户" class="headerlink" title="超级管理用户"></a>超级管理用户</h3><pre><code>mongo登录后，创建超级管理用户：
</code></pre><p><img src="https://i.imgur.com/4YilwiA.jpg" alt></p>
<pre><code>1. 设置角色和对应数据库的属性roles是一个数组，可以同时设置多个角色和对应数据库；
2. 角色设置之后，还需要修改配置文件：sudo vi /etc/mongod.conf，启用安全验证：
</code></pre><p><img src="https://i.imgur.com/jYs5Kj8.jpg" alt></p>
<pre><code>3. 修改了配置文件，必须重启MongoDB服务；
4. mongo命令登录后，并不能再查看所有数据库，必须使用身份验证的方式登录：
mongo -u 用户名(admin) -p 密码(123) --authenticationDatabase 验证的数据库(admin)
身份验证通过之后，就可以查看所有数据库，也可以切换到admin数据库进行操作。
5. 查看所有用户
    1. use admin：切换到admin数据库；
    2. db.system.users.find()：查看所有用户，以及用户的角色、对应的数据库。
</code></pre><h3 id="普通用户管理"><a href="#普通用户管理" class="headerlink" title="普通用户管理"></a>普通用户管理</h3><pre><code>1. 使用超级管理员登陆，查看当前数据库的用户：show users
2. 创建普通用户：
</code></pre><p><img src="https://i.imgur.com/dbIj8wu.jpg" alt></p>
<pre><code>3. 普通用户登录：mongo -u p1 -p 123 --authenticationDatabase py5
4. 该普通用户p1只对数据库py5有操作权限，是无法操作其他数据库的；
5. 在实际开发过程中，一个项目通常对应一个数据库，由超级管理员创建数据库，并分配数据库用户
   给项目开发者，保证开发者不能随便操作其他项目的数据库。
</code></pre><h2 id="复制-副本集"><a href="#复制-副本集" class="headerlink" title="复制-副本集"></a>复制-副本集</h2><pre><code>复制/副本集：提供数据的冗余备份，并在多个服务器上存储数据副本，提供数据的可用性，保证数据的
    安全性，允许从硬件故障和服务中断中恢复数据。
1. 主-从配置的服务器，应用程序访问A服务器(主)，B服务器定期从A服务器上读取数据，进行备份；
   如果A服务器宕机，应用程序会立即切换到B服务器(主)，待A服务器重启之后，则作为从服务器。
2. 复制的工作原理
    1. 复制至少需要两个节点A、B，常见的搭配方式：一主一从、一主多从；
    2. 主节点负责处理客户端请求，其他节点都是从节点，负责复制主节点上的数据；
    3. 从节点定期轮询主节点上记录的所有操作，然后对数据副本执行这些操作，保证从节点的数据
       与主节点一致；
3. 复制的特点
    1. N个节点的集群，任何节点都可以作为主节点，所有的写入操作都在主节点上；
    2. 自动故障转移，自动恢复，无宕机维护；
</code></pre><h3 id="设置复制节点"><a href="#设置复制节点" class="headerlink" title="设置复制节点"></a>设置复制节点</h3><pre><code>用xShell链接MongoDB服务器，完成节点设置，因为xShell支持对同一个ubuntu账户多开窗口；
1. 创建两个存放MongoDB数据库的文件夹t1、t2；
2. 在同一个Ip上启动两个MongoDB服务，指定不同的端口，使用不同的目录存放数据库，但既然做成
   一个副本集，replSet的名字必须要一致：
mongod --bind_ip 绑定Ip --port 绑定Port --dhpath 数据库的目录路径 --replSet 命名
3. 启动两个MongoDB服务：
</code></pre><p><img src="https://i.imgur.com/wBvqbAC.jpg" alt></p>
<pre><code>4. 重新指定了数据库目录，那么在启动MongoDB客户端连接时，也就不需要做身份验证了，但必须指定
   连接的Ip和Port：mongo --host Ip --port Port
5. 在终端上做初始化：rs.initiate()
    1. 在哪个终端上做初始化，那么它所连接的哪个MongoDB服务就设置成了主节点；
    2. 主节点设置成功之后，其命令提示符会发生变化；
    3. rs.status()：查看当前副本集的状态。
6. 在连接主节点的终端上添加副本集：rs.add(&apos;Ip:Port&apos;)，把另一个MongoDB服务作为从节点；
    1. 添加成功之后，连接从节点的终端提示符需要在Enter回车之后才会发生变化；
    2. 删除副本集：rs.remove(&apos;Ip:Port&apos;)
7. 自动备份数据
    1. 在主节点的终端上创建数据库，并插入数据；几秒钟之后，在从节点的终端上查询这些数据；
    2. 在从节点的终端上做查询操作，必须设置：rs.slaveOk()
8. 自动主从切换
    1. 重启主节点的服务，并退出主节点的终端和从节点的终端；
    2. 服务重启完成之后，再连接主节点和从节点，其命令提示符会交换，说明主从切换完成。
</code></pre><h2 id="数据备份与恢复"><a href="#数据备份与恢复" class="headerlink" title="数据备份与恢复"></a>数据备份与恢复</h2><pre><code>副本集可以实现自动数据备份，MongoDB也支持手动数据备份；
</code></pre><h3 id="数据备份"><a href="#数据备份" class="headerlink" title="数据备份"></a>数据备份</h3><pre><code>1. 无身份验证：mongodump -h db_host -d db_name -o db_directory
    1. db_host：服务器的地址，ip:port，如果是在服务器主机上直接操作，则省略-h部分；
    2. db_name：需要备份的数据库名称；
    3. db_directory：数据库的备份目录；
    4. 比如：mongodump -h 192.168.196.128:27017 -d test1 -o ~/Desktop/bak
2. 需要身份验证：mongodump -h db_host -u db_user(用户名) -p db_password(密码) 
    --authenticationDatabase db_name(验证的数据库) -d db_name -o db_directory
</code></pre><h3 id="数据恢复"><a href="#数据恢复" class="headerlink" title="数据恢复"></a>数据恢复</h3><pre><code>mongorestore -h db_host -d db_name --dir db_directory
1. mongoDB并不需要事先创建好数据库db_name，数据恢复时会自动创建；
2. 如果需要身份验证，可以直接使用超级管理员的账户，它能验证所有数据库。
</code></pre><h2 id="MongoDB与Python"><a href="#MongoDB与Python" class="headerlink" title="MongoDB与Python"></a>MongoDB与Python</h2><pre><code>1. 安装python包：sudo pip/pip3 install pymongo
2. 导入pymongo模块：from pymongo import *
3. 建立连接并创建客户端对象：
    1. 无安全认证：client=MongoClient(&apos;mongodb://Ip:Port&apos;)
    2. 有安全认证：client=MongoClient(&apos;mongodb://用户名:密码@Ip:Port/数据库名&apos;)
4. 获取数据库：db=client.数据库名
5. 获取集合：stu=db.集合名
</code></pre><h3 id="增删改查"><a href="#增删改查" class="headerlink" title="增删改查"></a>增删改查</h3><pre><code>1. 插入数据
    1. stu.insert_one({文档})，返回一个对象，其属性inserted_id可以获取文档的_id；
    2. stu.insert_many([{文档1}, {文档2}, {文档3} ...])，插入多条文档。
2. 修改数据
    1. stu.update_one({条件文档}, {&apos;$set&apos;:{新的文档}})：只更新第一条匹配的文档；
    2. stu.update_many({条件文档}, {&apos;$set&apos;:{新的文档}})：更新所有匹配的文档。
3. 删除数据
    1. stu.delete_one({条件文档})：只删除第一条匹配的文档；
    2. stu.delete_many({条件文档})：删除所有匹配的文档。
4. 查询数据
    1. find_one({条件文档})：返回匹配的第一条文档，字典类型；
    2. find({条件文档})：返回一个Cursor对象，直接对Cursor对象遍历，得到所有匹配的文档。
5. 排序：返回一个Cursor对象，ASCENDING 升序，DESCENDING 降序；
    1. 单属性：stu.find().sort(&apos;age&apos;, DESCENDING)，对查询的所有文档按照age降序；
    2. 多属性：stu.find().sort([(&apos;age&apos;, DESCENDING), (&apos;name&apos;, ASCENDING)])
6. 分页：stu.find().skip(2).limit(5)，返回一个Cursor对象；
</code></pre><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/08/08/MySQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/08/MySQL/" itemprop="url">MySQL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-08T00:00:00+08:00">
                2017-08-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="数据库简介"><a href="#数据库简介" class="headerlink" title="数据库简介"></a>数据库简介</h2><pre><code>每一种数据库的核心区别：对硬盘的读写算法不同；
    1. 数据是存在本地硬盘上的，以实现数据的持久化存储；
    2. 数据库并不是简单的IO操作，其读写硬盘数据的算法是经过优化的，读写更加高效；
    3. 数据库保证了数据的有效性，比如身份证号是唯一的，不允许录入重复的号码。
数据库主要分为两类：
    1. 文档型，比如移动端使用的轻量级数据库Sqlite，其实就是一个文件，但读写算法做了优化；
    2. 服务型，比如Oracle、MySQL、PostgreSQL，分为客户端和服务端，数据存储在服务器端，
       客户端通过TCP/IP协议链接，进行数据库的读写操作；
</code></pre><h3 id="E-R-模型"><a href="#E-R-模型" class="headerlink" title="E-R 模型"></a>E-R 模型</h3><pre><code>E-R模型针对的是关系型数据库，E：Entry(实体)，R：Relationship(关系)；
1. 当前物理的数据库都是按照E-R模型设计的，将一个实体转换为数据库的一个表，实体的属性转换为
   表中的字段；
2. 关系用于描述两个实体之间的对应规则：一对一、一对多、多对多；
3. 关系转换为表中的一个列，在关系型数据库中，一行就是一个对象；
</code></pre><h3 id="三范式"><a href="#三范式" class="headerlink" title="三范式"></a>三范式</h3><pre><code>数据库的设计需要遵循一定的规则，这些规则称为范式；
1. 第一范式(1NF)：列不可拆分
    1. 比如&quot;学生&quot;作为一个实体，其属性&quot;姓名&quot;是两个信息，可以设计成一列，也可以设计成两列，
    但是，对于学生信息，只需要维护&quot;姓名&quot;作为一列就足够使用了，而对于公安系统来说，则需要
    单独维护&quot;姓&quot;和&quot;名&quot;作为两列(两个字段)；
    2. &quot;不可拆分&quot;的标准在于，&quot;够用就行&quot;，基于当前的实际需求。
2. 第二范式(2NF)：唯一标识
    每个实体(表)都可以通过一个属性唯一的查找到，该属性就是表的唯一标识；
3. 第三范式(3NF)：引用主键
    针对的是关系，主键是一个表的唯一标识，引用另一张表的数据时，必须通过主键引用；
说明：后一个范式，都是在前一个范式的基础上建立的。
</code></pre><h3 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h3><pre><code>数据的完整性：保证数据正确有效，在创建表时，添加一些强制性验证，包括数据字段的类型、约束；
1. 字段类型
    1. 数字常用的类型：
        1. 整数：int
        2. 浮点数：decimal(m, n)，m 表示浮点数的位数，n 表示小数点后的位数；
    2. 字符串：char，varchar，text
        1. char(n)：如果字符个数少于 n，则在右侧补空格，强制使字符个数保持在 n 个；
        2. varchar(n)：与char的不同，不会自动补空格，存放的是字符的真实个数；
        3. text：字符个数不固定时使用，不限制字符的个数，比如描述信息；
        4. 另外，只要使用了字符串，必须统一编码格式，比如 utf-8；
    3. 日期：datetime
    4. 布尔类型：bit
        1. bit：存放二进制的比特位，默认存放 1 个比特位(0，1)；
        2. bit(8)：存放 8 个比特位，即一个字节；
        3. bit 的空间开销更小，比如性别(male，female)，字符串类型所占用的空间开销更大，
           既然性别只有两种状态，就可以使用 0 和 1 表示，用bit进行存储。
2. 约束
    1. 主键约束：primary key，主键不能重复，数据库通过主键查找数据的速度很快；
    2. 非空约束：not null，比如约束字段name不能为空，保存name为空的数据时，就会报错；
    3. 唯一约束：unique，不能出现重复的值；
        1. 与主键的区别是，一个实体可以有多个唯一约束，但只有一个主键；
        2. 物理上的存储结构是按照主键进行维护的，而不是按照唯一约束；
    4. 默认约束：default，用于设置默认值；
    5. 外键约束：foreign key
</code></pre><h2 id="MySQL基础"><a href="#MySQL基础" class="headerlink" title="MySQL基础"></a>MySQL基础</h2><pre><code>1. 在设计表时，通常预留一定数量的字段，以适应后期的设计变化，避免修改表的结构；
   因为表一旦设计完成，一般不会再增删字段，即使字段不再使用，也不会删除；
2. 物理删除：在删除表中的数据时，把数据从硬盘上直接删除，数据也就被永久性删除了；
3. 逻辑删除：在表中增加一个标识性字段isDelete，类型为bit，默认值为0；
    1. isDelete的值为0 表示数据存在，值为1 表示数据被删除；
    2. 在删除数据时，只需要把该条数据的isDelete设置为1 即可；
    3. 从数据库中读取数据时，只读取isDelete的字段值为0 的数据；
    4. 逻辑删除可以保护重要的数据不会因为某种原因被永久性删除。
4. mysql的默认端口是：3306
</code></pre><h3 id="图形化管理MySQL"><a href="#图形化管理MySQL" class="headerlink" title="图形化管理MySQL"></a>图形化管理MySQL</h3><pre><code>在Windows系统上使用MySQL管理软件SQLyog/Navicat for MySQL，图形化管理MySQL数据库；
1. 本地连接
    在Windows系统上安装MySQL，并启动MySQL服务：net start MySQL；
    使用管理软件Navicat可以直接建立MySQL连接。
2. 远程连接
    一台主机模拟远程连接：
        1. 在Windows系统上安装VW虚拟机；
        2. VW虚拟机上安装ubuntu Linux；
        3. ubuntu Linux系统上安装MySQL。
    1. MySQL默认不允许远程连接，必须设置为可远程连接，并重启MySQL；
    2. 远程连接之前，先确认Window系统与Linux系统可以通信：ping，测试连通性；
    3. 如果ping 失败，可能是因为Linux系统的Ip 与Window系统的Ip 不在同一网段；
       1. 执行 sudo dhclient 命令，重新动态分配Ip；
       2. 如果 sudo dhclient 执行失败，可以将VW虚拟机的网络适配器设置为桥接模式；
       3. 这两种方式执行完之后，最好重启一下mysql。
    4. ping 成功之后，使用Windows系统中的Navicat，远程连接Linux系统中的MySQL。
</code></pre><h3 id="命令管理MySQL"><a href="#命令管理MySQL" class="headerlink" title="命令管理MySQL"></a>命令管理MySQL</h3><pre><code>1. mysql --help：查看mysql命令文档；
2. 本地登录MySQL：mysql -uroot -p
    1. root：登录的用户名；  -p：回车后输入密码；
    3. 不指定端口号，表示使用mysql的默认端口：3306
3. MySQL客户端远程登录：
    1. 在开发过程中，数据库通常统一搭建在一台服务器上，需要远程连接；
    2. 远程连接的命令：mysql -hIP -uroot -p
    3. IP：要连接的主机Ip；  root：登录的用户名；  使用默认端口：3306
4. 退出登录：quit/exit
5. 查看版本：select version();
6. 显示当前时间：select now();
7. 登录mysql之后，操作MySQL的命令语句都以分号&quot;;&quot;结尾。
</code></pre><h4 id="数据库操作"><a href="#数据库操作" class="headerlink" title="数据库操作"></a>数据库操作</h4><pre><code>1. 创建数据库：create database 数据库名 charset=utf8;
2. 删除数据库：drop database 数据库名;
3. 切换数据库：use 数据库名;
4. 查看当前操作的数据库：select database();
5. 查看所有的数据库：show databases;
</code></pre><h4 id="表操作"><a href="#表操作" class="headerlink" title="表操作"></a>表操作</h4><pre><code>1. 查看当前数据库中所有的表：show tables;
2. 创建一个表：create table 表名(列及类型);
    mysql&gt; create table student(
        -&gt; id int auto_increment primary key,
        -&gt; name varchar(10) not null,
        -&gt; gender bit default 1,
        -&gt; birthday datetime);
    1. auto_increment：设置为自动增长；
    2. primary key：设置为主键，一个表只能有一个字段设置为主键；
    3. not null：字段的值不能为空；
    4. default 默认值：设置字段的默认值。
3. 查询一个表的结构：desc 表名;
4. 修改表：
    1. 更改字段名：alter table 表名 change 旧字段名 新字段名 新类型;
       如果只修改字段类型，则新字段名与旧字段名设置为同名；
       如果不需要修改类型，则把新类型设置为原字段类型。
    2. 增加一个新字段：alter table 表名 add 列名 类型;
       增加一个标识性字段并指定默认值：alter table 表名 add isDelete bit default 0;
    3. 删除字段：alter table 表名 drop 列名;
    4. 修改字段类型：alter table 表名 modify column 字段名 新类型;
5. 删除表：drop table 表名;
6. 更改表的名称：rename table 原表名 to 新表名;
7. 查看表的创建语句：show create table 表名;
</code></pre><h4 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h4><pre><code>1. 查看表中所有字段的数据：select * from 表名;
2. 添加数据：insert
    1. 全字段添加：insert into 表名 values(字段1的值, 字段2的值, ...);
        1. 先使用 desc 命令查看表的结构(列的顺序)，字段的值与字段的顺序必须一一对应；
        2. 主键字段id 虽然设置为auto_increment，仍然需要根据字段的顺序设置 id 的值，
           但是，id 的真实数据会以自动生成的为准，手动设置的值只是作为占位符，比如 0；
        3. 字符串和日期类型的数据，用单引号标识。
    2. 指定字段添加：insert into 表名(字段1, ...) values(值1, ...);
    3. 同时插入多条数据：
        1. insert into 表名 values(字段1的值, ...), (字段1的值, ...), ...;
        2. insert into 表名(字段1, ...) values(值1, ...), (值1, ...), ...;
3. 修改数据：update
    1. update 表名 set 字段1=值1, 字段2=值2, ... where 条件;
    2. 逻辑删除 id=2 的数据：update students set isDelete=0 where id=2;
    3. 只查看 isDelete=1 的数据：select * from students where isDelete=1;
4. 删除数据
    1. delete from 表名 where 条件;
    2. 物理删除 id=3 的数据：delete from students where id=3;
5. 数据备份与恢复
    1. 更换开发使用的服务器时，就需要对数据进行备份，并在另一台服务器上恢复数据；
    2. 备份数据，其实就是生成一个sql脚本，但该脚本中不包含创建数据库的SQL语句，所以在恢复
       数据时，要先创建数据库；
    3. 备份数据库需要有管理员权限：sudo -s，进入mysql目录：cd /var/lib/mysql
    4. 备份到桌面：mysqldump -uroot -p 数据库名 &gt; ~/Desktop/copy.sql
       输入mysql的登陆密码；
    5. 先登录mysql，创建一个新的数据库，退出mysql；
    6. 恢复数据：mysql -uroot -p 新数据库名 &lt; ~/Desktop/copy.sql，输入mysql的密码。
</code></pre><h2 id="查询：select"><a href="#查询：select" class="headerlink" title="查询：select"></a>查询：select</h2><pre><code>1. 查询指定字段的数据：select 字段1,字段2,... from 表名;
2. distinct：去除数据重复的行；
    1. select distinct id,name from students;
    2. id 是自增长的主键字段，不会重复，所以，即使 name 有重复的数据，也不会被筛选。
3. as：为查询的字段/表名取一个别名，可以更直观地显示查询结果，也方便后续的语句使用；
    1. select name as &apos;姓名&apos;,sex as &apos;性别&apos; from students;
    2. 显示查询结果时，字段name 以&quot;姓名&quot;显示，字段sex 以&quot;性别&quot;显示。
</code></pre><h3 id="条件：where"><a href="#条件：where" class="headerlink" title="条件：where"></a>条件：where</h3><pre><code>1. 比较运算符：=，&gt;，&gt;=，&lt;，&lt;=，!=/&lt;&gt;
2. 逻辑运算符：and，or，not
3. 模糊查询：like
    1. %：匹配任意多个字符；
        1. select * from students where name like &apos;李%&apos; or name like &apos;%豪%&apos;;
        2. 查询姓&quot;李&quot;，或者名字中带&quot;豪&quot;的学生。
    2. _：只匹配一个字符；
4. 范围查询：in，between...and...
    1. in：在一个非连续的范围内，select * from students where id in(1,3,6);
    2. between...and...：在一个连续的范围内，where id between 3 and 8;
5. 空判断：is null，is not null
</code></pre><h3 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h3><pre><code>1. 子查询：嵌套查询
    select *, (select count(*) from projects where user.id=projects.creator)
    as projectNum from user where delete!=1 limit 0,10
</code></pre><h4 id="优先级"><a href="#优先级" class="headerlink" title="优先级"></a>优先级</h4><pre><code>(...) &gt; not &gt; 比较运算符 &gt; 逻辑运算符
1. and 的优先级大于 or，如果希望先运算or，需要使用小括号改变优先级；
2. in、between...and... 与比较运算符是同级的。
</code></pre><h3 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h3><pre><code>聚合：为了快速得到统计数据，只显示统计的结果，而不展示统计出的原始数据；
1. count(*)：计算总行数，select count(*) from students; --&gt; 统计学生总数；
2. min/max(列名)：求此列的最小值/最大值；
3. sum(列名)：求和；
4. avg(列名)：求平均值；
</code></pre><h3 id="分组：group-by"><a href="#分组：group-by" class="headerlink" title="分组：group by"></a>分组：group by</h3><pre><code>1. select 列1,列2,聚合... from 表名 group by 列1,列2...
    1. 按照字段进行分组，在此字段的数据中，相同的数据被分为一组；
    2. 分组是为了更好的聚合，所以还会使用聚合函数统计数据。
2. 按照性别gender(bit类型)分类，并统计男女人数：
    select gender as &apos;性别&apos;,count(*) from students group by gender;
    count(*)：* 匹配的是每一类gender，计算每一类gender的数量。
3. 聚合与分组：当对表中的所有数据进行聚合时，通常不需要分组；如果是对表中的某些数据聚合，
    则需要考虑分组。
</code></pre><h4 id="数据筛选：having"><a href="#数据筛选：having" class="headerlink" title="数据筛选：having"></a>数据筛选：having</h4><pre><code>1. hanving 与 where
    1. where：对from 后面所指定的表进行数据筛选，属于原始数据的筛选；
    2. having：对 group by 的结果集进行筛选，having语句所使用的字段也必须在该结果集中；
    3. having 后面使用条件运算符与 where 的相同。
2. select 列1,列2,聚合... from 表名 group by 列1,列2... having 条件;
3. 统计男生的总人数：
    1. select count(*) from students where gender=1;
    2. select gender,count(*) from students group by gender having gender=1;
</code></pre><h3 id="排序：order-by"><a href="#排序：order-by" class="headerlink" title="排序：order by"></a>排序：order by</h3><pre><code>1. select * from 表名 order by 列1 asc/desc,列2 asc/desc...
    1. asc 升序，desc 降序，默认是升序排列；
    2. order by 是对最终的结果集进行排序的，所以必须放在 where、group by 的后面；
    3. 排序是为了更直观的查看数据。
2. 按照id 降序排列：select * from students where isDelete=1 order by id desc;
</code></pre><h3 id="分页：limit"><a href="#分页：limit" class="headerlink" title="分页：limit"></a>分页：limit</h3><pre><code>1. select * from 表名 limit start,count;
2. start 开始的索引(起始索引为0，与id无关)，count 条数；
3. 表中数据的索引是从 0 开始，而显示数据时，每一页的索引通常是从 1 开始的。
4. 一个完整的select语句，各个关键字的排列顺序如下：
    select distinct * from 表名 where ... group by ... having ... order by ...
    limit start,count;
5. 执行顺序：
    from 表名 --&gt; 获取最原始的数据集合 ==&gt; where --&gt; 对原始数据筛选，获取符合条件的行，
    组成新的结果集 ==&gt; group by --&gt; 对结果集进行分组，即合并行，得到一个新的结果集 ==&gt;
    select distinct * --&gt; 筛选出指定的字段，并去除重复的行，组成新的结果集 ==&gt; having
    --&gt; 再次对结果集筛选，得到新的结果集 ==&gt; order by --&gt; 对数据排序 ==&gt; limit ---&gt;
    分页显示数据
</code></pre><h2 id="关系"><a href="#关系" class="headerlink" title="关系"></a>关系</h2><pre><code>1. 表与表之间的关系类型：一对一，一对多，多对多；
2. 关系字段：用于引用另一张表的主键；
    1. 表A--&gt;表B 是一对一的关系，则关系字段存储在表A和表B任意一个都可以；
    2. 表A--&gt;表B 是一对多的关系，则关系字段存储在表B中；
    3. 表A--&gt;表B 是多对多的关系，则新建一张表，存储关系字段；
3. 关系不能闭合，比如表A与表B、表B与表C、表A与表C 都有关系，在设计表之间的关系时，一定不能
   让关系闭合；根据实际的需求，把经常操作的两张表建立关系，比如 A--&gt;B--&gt;C，A和C不能再直接
   建立关系，而是通过表B进行关联。
4. 分析过程：确定两个实体是否存在关系 --&gt; 确定关系的类型 --&gt; 在哪个实体中创建关系字段；
5. 外键约束
    1. 创建外键的方式：
        1. 创建表时：foreign key(关系字段) references 被关联的表名(被关联的字段);
        2. 表已创建：alter table 表名 add constraint 外键名 foreign key(关系字段)
            references 被关联的表名(被关联的字段);
            外键名：为外键定义的名字，可以不指定，mysql会自动创建一个。
    2. 作用：建立关系字段之后，为了保证关系字段的数据正确、有效；
    mysql&gt; create table scores(
        -&gt; id int auto_increment primary key not null,
        -&gt; score decimal(4,1),
        -&gt; stuid int,
        -&gt; subid int,
        -&gt; foreign key(stuid) references students(id),
        -&gt; foreign key(subid) references subjects(id));
    3. 被关联的字段通常是被关联表的主键字段.
6. 外键的级联操作
    1. 表A 关联了表B，如果删除了表B 的相关数据时，会抛出异常；所以，通常使用逻辑删除。
    2. 级联操作的类型：
        1. restrict：限制，默认类型，会抛出异常；
        2. cascade：级联，如果删除/更新了表B 的相关数据，则表A中的记录也会被删除/更新；
        3. set null：将外键设置为空；
        4. no action：什么都不做。
    3. 创建了表之后，修改外键为cascade：alter table scores add constraint 外键名
    foreign key(关系字段) references 被关联的表名(被关联的字段) on delete cascade
    on update cascade;
    4. 在设计表时，如果表的某个字段被外界所关联，通常设置为逻辑删除即可，而不使用级联操作
</code></pre><h3 id="连接查询"><a href="#连接查询" class="headerlink" title="连接查询"></a>连接查询</h3><pre><code>当查询的字段是外键时，需要使用连接查询；
    1. 表A inner join 表B on：只显示表A和表B匹配的字段；
    2. 表A left join 表B on：除了显示匹配的字段，还包括表A 中独有的数据，未匹配的数据用
       null占位；
    3. 表A right join 表B on：除了显示匹配的字段，还有表B 中独有的数据；
</code></pre><p><img src="https://i.imgur.com/1FIcRlR.jpg" alt></p>
<pre><code>1. inner join 表名 on 关系
    1. select students.name,subjects.title,scores.score from scores
    inner join students on scores.stuid=students.id
    inner join subjects on scores.subid=subjects.id;
</code></pre><p><img src="https://i.imgur.com/wL7rTfI.jpg" alt></p>
<pre><code>    2. 调换表名&quot;scores&quot;和&quot;students&quot;的位置，结果是等效的，只要保证表名和关系相对应即可；
    比如&quot;students&quot;和&quot;subjects&quot;是不能交换位置的，因为会造成 on 后面的关系不对应。
2. 计算平均分，并排序：
    select students.name as &apos;姓名&apos;,avg(score) as avg1 from scores
    inner join students on scores.stuid=students.id
    group by stuid order by avg1;
</code></pre><p><img src="https://i.imgur.com/7iV6Enj.jpg" alt></p>
<pre><code>1. group by stuid 等效于：group by students.id；
2. inner join 连接了students表，就可以通过 &quot;students.字段&quot; 使用students表的任意
字段，也就可以获取students表的任意字段值。
</code></pre><h3 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h3><pre><code>视图是对 select 查询语句的封装；
1. 创建一个视图：create view 视图名 as select语句;
2. 修改视图：alter view 视图名 as select语句;
3. 执行视图：select * from 视图名;
4. show tables：可以查看所有的表和视图。
</code></pre><h3 id="自关联"><a href="#自关联" class="headerlink" title="自关联"></a>自关联</h3><pre><code>对于高性能的数据库，一个表可以存数十万条数据，如果相关联的两张表所存储的数据总量比较少，
则可以合成一张表，比如国内的省、市、县，其数量基本是固定的，设计成3个表会造成性能的浪费，
就可以使用自关联的方式，合并成一个表。
1. 自关联：表的外键关联自身的字段；
</code></pre><p><img src="https://i.imgur.com/KhGDLuq.jpg" alt></p>
<pre><code>省、市、县中，省是最高一级，其pid设置为null/0
2. 在当前使用的数据库中，导入一个sql脚本：source xx.sql;
</code></pre><p><img src="https://i.imgur.com/JDIztZW.jpg" alt></p>
<pre><code>3. 在查询省市县时，因为是在同一张表，可以使用嵌套查询/子查询，但语句逻辑会很混乱，所以仍然
   使用连接查询，只查询河南省的市：
</code></pre><p><img src="https://i.imgur.com/CMHLT69.jpg" alt></p>
<pre><code>4. 查询周口市的所有县区：
</code></pre><p><img src="https://i.imgur.com/TAfCbHY.jpg" alt></p>
<h2 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h2><pre><code>内置函数可以将字段名当作参数，MySQL提供了很多内置函数；
1. 字符串常用的内置函数
    1. select ASCII(str)：返回第一个字符在ASCII码表中对应的数值；
    2. select char(int)：数值在ASCII码表中对应的字符；
    3. select concat(12,&apos;ab&apos;,13)：拼接成字符串，12ab13；
    4. 截取字符串：对于字符串位置的操作，第一个字符的位置为 1
        1. select left(str, len)：字符串str左起截取len个字符；
        2. select right(str, len)：右起截取len个字符；
        3. select substring(str, pos, len)：从第pos个字符开始，截取len个字符；
    5. 去除空格
        1. ltrim(str)：返回一个去除了左边空格的新字符串；
        2. rtrim(str)：去除右边的空格；
        3. trim(str)：去除左右两边的空格；
        4. trim(orientation remstr FROM str)：指定删除某一侧的remstr；
        orientation：both(两侧的都删除)，leading(删除左侧的)，trailing(删除右侧的)
        select trim(both &apos;x&apos; from &apos;xxxxbaxlxxxx&apos;)：删除两侧的&apos;x&apos; --&gt; &apos;baxl&apos;
    6. select space(n)：返回一个由n个空格组成的字符串；
    7. replace(str, oldstr, newstr)：将str的字串oldstr替换成newstr；
    8. 大小写：lower(str)、upper(str)
2. 数学函数
    1. select abs(n)：求绝对值；
    2. mod(m, n)：求余数，等效于 select m%n;
    3. floor(n)：不大于n的最大整数，floor(2.3) --&gt; 2；
    4. ceiling(n)：不小于n的最小整数，ceiling(2.3) --&gt; 3；
    5. round(n, d=0)：四舍五入的值，n 表示原数，d 表示小数的个数；
    6. pow(m, y)：m 的 n 次幂；
    7. PI()：圆周率；
    8. rand()：随机数，0-1 之间的浮点数；
    9. log(x)，sin(x)，radians(x) ...
3. 日期时间函数
    1. year(data)、month(data)、day(data)：年份、月份、日期；
    2. hour(time)、minute(time)、second(time)：时0-23、分0-59、秒0-59
    3. date_format(date, format)：日期格式化；
    format：
        1. %Y：完整的年，比如2016；  %y：简略的年，只保留后两位；
        2. %m：月份1-12；   %d：日期
        3. %H：24小时制0-23；   %h：12小时制1-12；
        4. %i：分钟0-59；   %s：秒钟0-59；
    select date_format(&apos;2016-12-21&apos;, &apos;%Y年%m月%d日&apos;)：2016年12月21日；
    4. current_date()、current_time()：获取当前日期、时间，等效于 now();
    5. 时间日期也可以用 +、- 进行计算；
        1. SELECT &apos;2008-12-31 23:59:59&apos; + INTERVAL 1 SECOND; --&gt; 加1秒；
        2. SELECT &apos;2008-12-31 23:59:59&apos; + INTERVAL 1 DAY; --&gt; 加1天。
</code></pre><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><pre><code>1. select语句只是查询数据，并不会影响数据；当对数据进行更改操作时，为了保证执行的有效性，
   也即，要么成功，要么全部失败，不会只成功一部分，这就是事务。
2. 事务的四大特性：原子性、一致性、隔离性、持久性
3. 表的类型(引擎)必须是：innodb、bdb，才能使用事务；
    1. mysql创建的表，默认使用的是InnoDB；
    2. 不同的引擎，其性能的侧重点是不同的；
    3. show create table 表名：查看创建表的结构，也包括表的引擎；
    4. 修改表的引擎：alter table 表名 engine=innodb;
4. 使用事务：begin(开启)，commit(提交)，rollback(回滚)
    1. begin：开启事务，在内存中创建一个表，对数据的操作不会影响物理内存中的表；
    2. commit：提交事务，修改物理内存中的表；
    3. rollback：放弃操作，关闭事务；
</code></pre><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><pre><code>1. 当数据库中的数据量很大时，查找数据会变得很慢，索引用于提高数据访问的性能；
   比如，在一本汉语字典的前几页，标注有拼音/笔画查找，这就是索引；
2. 主键是一种特殊的索引，在数据库中，默认是按照主键存储的；
3. 索引的创建，也会增加物理开销，要合理选择字段/列的数据类型
    1. 越小的数据类型通常会更好，在磁盘、内存和CPU缓存中所占用的空间更少，处理更快；
    开销：bit &lt; int &lt; decimal
    2. 简单的数据类型更好：字符串在底层需要转换，整型数据则更简单，处理开销更小；
    3. 尽量避免NULL：尽量设置字段为NOT NULL，使用0、一个特殊值、空字符串代替NULL；
    在MySQL中，含有NULL的列很难进行优化，因为它使索引、索引统计信息以及比较运算更加复杂。
4. 索引通常并不是在设计数据库时添加的，而是在后期数据量太大、对数据库进行优化时添加，对那些
   where语句中频繁使用的字段创建索引；
5. where语句是从第一行开始筛选的，即使在中间遇到了匹配的数据，也会执行到最后一行，因为匹配
    的数据可能有多行；但是，一旦为 where语句中使用的字段增加了索引，它会直接找到匹配的行，
    而不会再继续执行；也即，优化数据库其实就是优化耗时的 where语句。
    1. 单列索引：为 where语句后的每个字段都创建一个索引；
    2. 组合索引：where后的所有字段只创建一个索引。
6. 语句的顺序也会影响索引的效果，比如 where gender=0 and isdelete=0 and id&gt;8;
    1. and 是与运算，= 表示唯一的值，&gt; 表示一个范围，索引只对gender和isdelete有效，所以
    只创建gender和isdelete的索引即可；
    2. where gender=0 and id&gt;8 and isdelete=0：会造成isdelete的索引无效；
    3. 尽量避免使用 or 运算符，因为 or 也会造成字段的索引无效。
</code></pre><h3 id="操作索引"><a href="#操作索引" class="headerlink" title="操作索引"></a>操作索引</h3><pre><code>1. 查看表的所有索引：show index from 表名;
2. 创建索引：create index 索引名 on 表名(字段(长度));
    1. 长度是创建字段时指定的长度，一般字符串需要显示指定长度，整型则不需要；
    2. 为多个字段创建一个索引： ... on 表名(字段1(长度),字段2(长度)...);
3. 删除索引：drop index 索引名 on 表名;
4. 索引虽然大大提高了查询速度，但同时也会降低更新表的速度；
    1. 执行INSERT、UPDATE和DELETE时，MySQL不仅要保持数据，还要保存索引文件；
    2. 索引文件也会占用磁盘空间。
</code></pre><h3 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h3><pre><code>1. 开启执行时间的检测：set profiling=1;
2. 执行SQL语句之后，查看执行时间：show profiles;
</code></pre><p><img src="https://i.imgur.com/LMo4FE1.jpg" alt></p>
<h2 id="Python与MySQL的交互"><a href="#Python与MySQL的交互" class="headerlink" title="Python与MySQL的交互"></a>Python与MySQL的交互</h2><pre><code>1. 安装mysql模块：
    1. python2环境：sudo apt-get install python-mysqldb --&gt; import MySQLdb
    2. python3环境：安装pymysql模块 --&gt; import pymysql
2. python3环境下，操作数据库，插入一条数据：
</code></pre><p><img src="https://i.imgur.com/pEjXMMH.jpg" alt></p>
<pre><code>    1. connect连接数据库时，默认开启事务，必须执行 commit() 才有效。
    2. conn.rollback()：回滚，放弃之前的操作。
1. 参数化
    参数化是为了避免SQL语句的攻击，比如SQL注入；参数化会调用内置的函数，检查输入的数据；
    sql = &quot;insert into students(name) VALUES(%s)&quot;
    param = [&apos;LiLi&apos;]  --&gt;列表
    cursor.execute(sql, param)
    1. %s 只是用于占位，与格式化输出的 %s 并不相同；
    2. execute(sql, param)：param 可以是一个列表/元组/字典； 
2. 查询：与增/删/改不同，select语句还会返回查询的结果
    1. cursor.fetchone()：返回一行数据的查询结果，元组类型，数据不存在则返回None；
    2. cursor.fetchall()：多行数据的查询结果，元组类型，其元素也是元组类型；
    3. scroll(value, mode=&apos;relative&apos;)：将行指针移动到指定位置，mode表示移动的方式；
        1. relative 是默认值，表示基于当前行移动到value，value为正数，则指针向下移动，
        value为负数，则指针向上移动；
        2. mode=&apos;absolute&apos;，基于第一行的位置，第一条数据的位置为 0.
    cursor = conn.cursor()
    cursor.execute(&quot;select * from students&quot;)
    result = cursor.fetchall()
3. 在操作数据库时，尽量晚打开、尽量早关闭。
</code></pre><h3 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h3><pre><code>有些数据并不是直接存入数据库的，比如用户的登录密码，必须加密之后再存入数据库。
1. python中的加密模块：import hashlib
2. hashlib模块包含多种加密：md5、sha1、sha224、blake2b ...
3. sha1 相当于是 md5 的加强版；md5加密后的字符固定是32个，sha1加密后的字符是40个。
    from hashlib import sha1
    pwd = &quot;abcd123&quot;   s1 = sha1()
    s1.update(pwd.encode(&apos;utf8&apos;))  --&gt; python3的字符串要先编码
    pwd2 = s1.hexdigest()  -------&gt; 加密完成
1. password使用sha1加密之后，生成的字符固定为40个，则password的类型定义为char(40)；
2. s1.digest()：生成的是byte类型数据，十六进制；
</code></pre><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/08/07/数据结构与算法2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/07/数据结构与算法2/" itemprop="url">数据结构与算法2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-07T00:00:00+08:00">
                2017-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><pre><code>排序算法的稳定性：排序前后的元素序列是一致的，则该排序算法是稳定的；反之，该排序算法不稳定；
</code></pre><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><pre><code>原理：
    1. 比较两个相邻的元素，如果第一个比第二个大(升序)，则交换位置；
    2. 每次遍历筛选出一个最值，下一次循环不再遍历筛选出的最值；
    3. 冒泡排序的算法是稳定的；
</code></pre><p><img src="https://i.imgur.com/tlAdZHD.jpg" alt></p>
<p><img src="https://i.imgur.com/MdvaVMb.jpg" alt></p>
<pre><code>时间复杂度：
    1. 最优：O(n)，数列本身就是有序的，第一次遍历不会有任何交换，则不再遍历；
    2. 最坏：O(n^2)
</code></pre><h3 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h3><pre><code>原理：
    1. 第一次遍历，筛选出最大的元素(升序)，并与最后一个元素交换位置；
    2. 第二次循环只遍历剩下的元素，筛选出最大的，并与倒数第二个元素交换位置，依次类推；
</code></pre><p><img src="https://i.imgur.com/jiU8SOe.jpg" alt></p>
<pre><code>1. 时间负责度：最优和最差都是O(n^2)
2. 选择排序的算法是不稳定的：[46, 4, 6, 2, 46, 5, 1]
    在升序排列过程中，第一个46 会和 1 交换位置，所以第二个46 一定会排在第一个46 的后面，
导致排序前后的元素顺序不一致。
</code></pre><h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><h3 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h3><h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><h2 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h2><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/08/06/数据结构与算法1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/06/数据结构与算法1/" itemprop="url">数据结构与算法1</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-06T00:00:00+08:00">
                2017-08-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><pre><code>例：a + b + c = 1000，a**2 + b**2 = c**2
1. 最直观的解决方式：
</code></pre><p><img src="http://i.imgur.com/a8NVFqV.jpg" alt></p>
<pre><code>这种方式的计算，消耗了超过4分钟的时间，效率极其低下；
2. 改进版：
</code></pre><p><img src="http://i.imgur.com/UB7DEN1.jpg" alt></p>
<pre><code>只消耗了1秒左右的时间，大大提高了效率！
</code></pre><h3 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h3><pre><code>1. 计算机的配置不同，执行相同的代码所消耗的时间也就不同，但执行基本运算的数量是相同的；
   所以，通过对比执行基本运算的数量，就可以看出两种算法的优劣；
2. 时间复杂度
    1. 执行基本运算的数量，就是时间复杂度，表示方法：大&quot;O&quot;表示法
    2. 最优/最坏时间复杂度：算法完成工作最少/最多需要多少基本运算
    3. 时间复杂度的计算原则：
        1. 基本语句，即只有常数项，时间复杂度为 O(1)；
        2. 顺序结构，时间复杂度按加法计算；
        3. 循环结构，时间复杂度按乘法计算；
        4. 分支结构，时间复杂度取最大值；
        5. 判断一个算法的效率，通常只关注运算数量的最高次项，其他次要项和常数项可以忽略；
        6. 没有特殊说明时，分析一个算法的时间复杂度，指的都是最坏时间复杂度。
3. 方式1和方式2的时间复杂度：
    1. T1 = 1000 * 1000 * 1000 * 2 ---&gt; T(n^3) * 2 ---&gt; O(n^3)
    2. T2 = 1000 * 1000 * 3 ---&gt; T(n^2) * 3 ---&gt; O(n^2)
    3. O(n^3)是O(n^2)的n倍，所以方式2的效率更高。
4. 常见的时间复杂度
</code></pre><p><img src="http://i.imgur.com/RWZzjk3.jpg" alt></p>
<h3 id="Python内置性能分析"><a href="#Python内置性能分析" class="headerlink" title="Python内置性能分析"></a>Python内置性能分析</h3><pre><code>timeit模块：用来测试一小段python代码的执行速度；
1. class timeit.Timer(stmt=&quot;&quot;, setup=&quot;&quot;, timer=&lt;timer function&gt;)
    1. stmt：要测试的代码语句，比如一个函数；
    2. setup：运行代码时需要的设置，比如导入被测试的函数，即使测试的是当前模块的函数，也是
            需要导入的，因为timeit的测试其实是在一个独立的模块内进行的；
    3. timer：可选参数，是一个定时器函数，与系统平台有关；
2. Timer().timeit(number=1000000)：执行测试，number设置的是测试次数，默认值为1000000，
    返回的是平均耗时；
3. 列表、字典、元组、集合，其实是python封装后的工具，测试列表操作的时间复杂度：
</code></pre><p><img src="http://i.imgur.com/ZI7yOww.jpg" alt></p>
<pre><code>从测试结果可以看出：
    1. &quot;+&quot; 的效率是极低的，而 &quot;+=&quot; 是优化后的运算符，效率很高，所以尽量避免使用&quot;+&quot;；
    2. 函数并不是基本运算，函数体的数据结构，决定了函数效率的高低，比如：append() 的效率要
       比insert()高很多，是因为append() 的时间复杂度为 O(1)，insert()的时间复杂度为O(n)
</code></pre><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><pre><code>1. 数据结构是指数据元素之间的关系，是数据的组织方式，比如python中内置的列表、字典；
2. 算法是为了解决实际问题而设计的，数据结构是算法需要处理问题的载体；
3. 程序 = 数据结构 + 算法
4. 抽象数据类型(ADT)：指一个数学模型以及定义在此模型上的一组操作，也就是把数据类型和数据运算
   进行封装；
5. 常见的数据运算：插入、删除、修改、查找、排序。
</code></pre><h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><pre><code>内存：是一个连续的存储单元，以字节为基本单位，1字节对应8个比特位，每个字节又对应一个十六进制
    的地址编号；计算机在读取数据时，是先找到数据对应的内存地址，再按照字节读取数据；
类型本质：
    1. 任何数据在内存中都是以二进制形式存储的，类型决定了一个数据在内存中占多少个字节；
    2. 计算机从内存中读取到二进制数据时，该怎么转换，然后输出到屏幕上。
所有的高级数据结构都是由基本的数据类型构成的，python中的列表、字典等都是封装后的高级数据结构。
</code></pre><h3 id="线性表"><a href="#线性表" class="headerlink" title="线性表"></a>线性表</h3><pre><code>1. 在程序中，经常需要将一组数据元素作为整体管理和使用，这样一组数据元素可以看作是一个序列，
用元素在序列中的位置和顺序，表示数据之间的某种关系，这样的数据组织形式，就可以抽象为线性表；
2. 线性表是最基本的一种数据结构，根据线性表的实际存储方式，又可以分为顺序表和链表；
</code></pre><h3 id="顺序表"><a href="#顺序表" class="headerlink" title="顺序表"></a>顺序表</h3><pre><code>顺序表：将元素有序地存放在一块连续的存储区里，元素间的顺序关系由它们的存储顺序表示。
</code></pre><h4 id="顺序表的基本形式"><a href="#顺序表的基本形式" class="headerlink" title="顺序表的基本形式"></a>顺序表的基本形式</h4><pre><code>1. 基本形式之一：
    1. 用顺序表存储一组整型数据：Li = [2, 390, 78, 1212]，在32位机上，一个整型占4个字节，
       1字节占8个比特位，也即一个整型占32位；
    2. 存储4个整型，需要向操作系统申请16Byte，操作系统会一次性返回一段连续的存储空间；
    假定起始地址是0x23，那么存储每个整数的起始地址为：0x23 --&gt; 0x27 --&gt; 0x31 --&gt; 0x35
    3. 顺序表的引用Li，指向的就是存储空间的起始地址：0x23； Li[0]获取元素时，先查看Li指向的
    内存地址0x23，角标表示内存地址的偏移量，角标为0 表示取值的内存地址为0x23+0*4Byte=0x23；
    同理，Li[3]取值的内存地址为0x23+3*4Byte=0x35；
2. 基本形式之二：元素外置的顺序表
    顺序表在存储不同数据类型的数据时，元素的地址是随机的，所以连续的存储空间存放的不再是元素，
    而是元素的地址；
    1. 用顺序表存储一组不同数据类型的数据：Li = [12, &quot;ab&quot;, 1.11]，虽然不同的数据类型占用的
    字节是不同的，但是内存地址占用的字节是一定的，32位机上的内存地址占用4个字节；
    2. 假定元素12、&quot;ab&quot;、1.11在内存中的起始地址分别为 0x100、0x200、0x53，那么，在顺序表向
    操作系统申请的连续存储区里，所存储的数据就是：0x100，0x200，0x53；
    3. 假定连续存储区的起始地址是0x23，那么存储每个元素地址的起始地址依次为：0x23 --&gt; 0x27
    ---&gt; 0x31； Li指向连续存储区的起始地址：0x23； Li[0]的指向：0x23 --&gt; 0x100 --&gt; 12
</code></pre><h4 id="顺序表的结构"><a href="#顺序表的结构" class="headerlink" title="顺序表的结构"></a>顺序表的结构</h4><pre><code>1. 一个完整的顺序表包括两部分：表头，数据区；
    1. 表头用于记录关闭顺序表的整体信息，主要包括顺序表的总容量和当前的元素个数；
    2. 数据区也就是存储元素的部分；
2. 顺序表的两种基本结构：一体式结构、分离式结构
</code></pre><p><img src="http://i.imgur.com/csOu5lo.jpg" alt></p>
<pre><code>1. 一体式结构的整体性更强，易于管理；缺点在于，顺序表一旦创建，元素存储区就固定了，假定顺序表
   的最大容量是5，如果要继续存入第6个元素，就需要重新申请数据区，又因为表头和数据区在一段连续
   的存储区，就只能搬迁整个顺序表，表头的内存地址也随之变化；
2. 分离式结构的顺序表，数据区在另一个独立的存储空间里，表头信息除了总容量和元素个数，还存储了
   数据区的起始地址；对于总容量为5的顺序表，继续存储第6个元素时，只需要搬迁数据区、修改表头中
   的起始地址即可，不必搬迁表头；所以，分离式结构的顺序表又称为动态顺序表。
3. 动态顺序表的扩充策略：
    1. 线性增长：每次重新申请数据区时，固定扩充一定的数目，比如每次都是在原来的基础上申请10个
       元素位置；这种方式虽然节省空间，但扩充操作频繁；
    2. 倍数增长：每次扩充都是加倍，空间换时间：虽然浪费了空间，但避免了频繁扩充，节省了时间。
</code></pre><h4 id="顺序表的操作"><a href="#顺序表的操作" class="headerlink" title="顺序表的操作"></a>顺序表的操作</h4><pre><code>1. 增加元素
</code></pre><p><img src="http://i.imgur.com/blQf5zl.jpg" alt></p>
<pre><code>    时间复杂度依次为O(1)、O(1)、O(n)，非保序的并不常见；
2. 删除元素
</code></pre><p><img src="http://i.imgur.com/TwUnFOS.jpg" alt></p>
<pre><code>时间复杂度依次为O(1)、O(1)、O(n)
</code></pre><h4 id="Python中的顺序表"><a href="#Python中的顺序表" class="headerlink" title="Python中的顺序表"></a>Python中的顺序表</h4><pre><code>1. Python中的列表和元组，采用的都是顺序表技术实现的，而且都是保序的；
2. 元组是不可变类型，虽然不支持改变其内部的任何操作，但其他方面与列表类似；
2. 列表是一种采用分离式结构实现的动态顺序表，所以append()的效率比insert()要高，pop()的效率
   比pop(index)的效率要高；
3. 列表采用的策略：
    1. 在创建一个空列表或者很小的一个列表时，系统会分配一块能容纳8个元素的存储区；
    2. 在执行append()/insert()时，如果存储区已满，则重新申请一块4倍大的存储区；
    3. 如果列表的容量已经很大了，则采用1倍大的策略进行申请，避免出现过多空闲的存储位置。
</code></pre><h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><pre><code>1. 链表的存储区不是连续的，也不会因为扩充存储区而搬迁数据；
2. 每增加一个元素，就创建一个节点，节点其实就一块存储区；
3. 链表可分为单链表和双链表。
</code></pre><h4 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h4><pre><code>单链表节点的构成：数据区和链接区，分别存储数据元素和下一个元素的内存地址；
1. 在python中，引用的本质就是，保存值的内存地址，比如 a=10，内存a 保存的是10 的内存地址；
2. 链接区就相当于是一个引用，指向下一个节点；
3. 当前节点指向的下一个节点，称为后继节点；
</code></pre><p><img src="https://i.imgur.com/qFWwe2p.jpg" alt></p>
<pre><code>变量p 指向链表的头节点，从p 出发，能找到链表的任意节点；

1. 节点的实现：
</code></pre><p><img src="https://i.imgur.com/2C7UTHH.jpg" alt></p>
<pre><code>2. 单链表的实现：
</code></pre><p><img src="https://i.imgur.com/tG8Nqbo.jpg" alt></p>
<pre><code>3. 链表与顺序表
    1. 链表失去了顺序表随机读取的有点，同时链表的节点指针域cursor也增加了空间开销，但链表
       对存储空间的使用相对灵活；
    2. 时间复杂度
</code></pre><p><img src="https://i.imgur.com/ZkKuEoX.jpg" alt></p>
<pre><code>    1. 链表和顺序表在插入/删除时，虽然时间复杂度都是O(n)，但其原理是完全不同的；
    2. 链表的主要耗时操作是遍历查找，插入/删除操作的时间复杂度为O(1)；
    3. 顺序表查找快，主要耗时操作是插入/删除时的拷贝覆盖。

单向循环链表
    1. 对于一个单链表，让其尾节点的链接区指向头节点，称之为单向循环链表；
    2. 如果只有一个节点，其链接区指向自身。
</code></pre><h4 id="双链表"><a href="#双链表" class="headerlink" title="双链表"></a>双链表</h4><pre><code>双链表节点的构成：前驱链接区(指向前一个节点)，数据区，后继链接区(指向下一个节点)
1. 当前节点指向的前一个节点，称为前驱节点，指向的下一个节点，称为后继节点；
2. 与单链表的操作相比，在插入和删除时，双链表还需要修改前驱链接区。
</code></pre><h3 id="栈与队列"><a href="#栈与队列" class="headerlink" title="栈与队列"></a>栈与队列</h3><pre><code>栈和队列都是一种数据结构，可以使用顺序表/链表实现；
</code></pre><h4 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h4><pre><code>栈：LIFO，后进先出，只允许在容器的一端(栈顶)进行操作，确定了一种默认的访问顺序；
使用Python中已有的顺序表：列表，实现栈结构：
</code></pre><p><img src="https://i.imgur.com/JVWbZhg.jpg" alt></p>
<h4 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h4><pre><code>队列：FIFO，先进先出，只允许在一端(队尾)进行插入，在另一端(队头)进行删除；
使用列表实现队列结构：
</code></pre><p><img src="https://i.imgur.com/NmNwfwj.jpg" alt></p>
<pre><code>1. append() 和 pop() 的时间复杂度是O(1)，而insert() 和 pop(index) 的时间复杂度是O(n)，
   也即，出队和入队总有一个操作的时间复杂度是O(n)；
2. 如果入队的操作大于出队，则选择 append() 和 pop(index) 的组合；反之，则选择 insert() 和
   pop() 的组合。

双端队列：同时具有队列和栈的特性，队头和队尾都能入队和出队。
</code></pre><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/08/05/Web服务器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/05/Web服务器/" itemprop="url">Web服务器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-05T00:00:00+08:00">
                2017-08-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h2><pre><code>1. HTTP协议规定的是：客户端与服务器端之间的数据传输规则，也即，规定的是数据内容的格式；
2. 对于客户端，除了浏览器，一些手机APP，如淘宝，京东等，在访问服务器时，也应用了HTTP协议，
   也即，HTTP协议已经超越了浏览器网页的应用；
3. HTTP协议的底层使用的还是TCP协议，也即，服务器的数据处理工作就在clientSocket.recv()与
   clientSocket.send() 两个函数之间；
4. HTTP协议规定的换行符是：\r\n
5. HTTP是无状态的：同一个客户端请求完数据，四次挥手断开链接，再次建立链接时，HTTP并不知道
   是不是同一个客户端，HTTP服务器并不关心是哪个客户端访问的。
6. 为了减少TCP的3次握手和4次挥手，HTTP1.1版本开始，默认使用长连接；
    1. 使用长链接的HTTP协议，会在请求头/响应头加入：Connection: keep-alive
    2. 但是，keep-alive 并不会永久保持链接性，可以在Server端设置链接的时间；
    3. 长连接的HTTP虽然复用了传输通道，但仍然是无状态的。
</code></pre><h3 id="请求头和响应头"><a href="#请求头和响应头" class="headerlink" title="请求头和响应头"></a>请求头和响应头</h3><pre><code>访问百度baidu.com时，客户端发送的请求头与服务器端发送的响应头：
</code></pre><p><img src="http://i.imgur.com/RoVYhU0.jpg" alt></p>
<pre><code>1. HTTP四种基本的请求方式：GET、POST、PUT、DELETE，分别对应：查、改、增、删
2. 增、删、改、查的操作，其实都可以通过GET/POST完成；
3. 其他请求方式：OPTION(获取选项)、HEAD(获取头) ...
</code></pre><p><img src="http://i.imgur.com/tnQ9jFK.jpg" alt></p>
<pre><code>1. 请求头和响应头都是一个字符串，通过&quot;\r\n&quot;实现每一项的换行；
2. 客户端的请求内容在请求体中，请求体位于请求头下面，中间用一个空行(&quot;\r\n&quot;)进行分割；
3. 请求头的数据类型是字符串，而且是字典的格式，但请求体的数据类型和数据大小都是不固定的，
   所以在请求头中，会用&quot;Content-Length&quot;指定请求体的数据大小；
4. 同理，响应体也在响应头的下面，中间用一个空行(&quot;\r\n&quot;)进行区分。
</code></pre><h3 id="URL、URI、URN"><a href="#URL、URI、URN" class="headerlink" title="URL、URI、URN"></a>URL、URI、URN</h3><pre><code>URL和URN是URI的子集
1. URI：Web地址的基本形式，资源标识符；
2. URL：L代表Location，资源的位置定位，域名后面的部分就是请求的资源在服务器端存放的位置；
3. URN：N代表Name，资源的名字定位，根据资源的名字查找，不再受资源位置的限制，URL的升级版。

用百度搜索&quot;abc&quot;的地址栏：https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=0&amp;...
1. URL：https://www.baidu.com/s，请求的资源在服务器端的 s 目录下；
2. &quot;?&quot;后面是GET请求方式需要提交给服务器的参数，因为GET请求不会把参数放在请求体中；
3. &quot;&amp;&quot;：用于连接多个参数;
4. HTTP协议并没有规定URL的长度，GET请求可提交的数据大小是浏览器与服务器约定的，因为浏览器上的
   地址栏长度是有限的。

Spider：蜘蛛，爬虫，也就是一个客户端，接收一个链接地址，向链接地址对应的服务器发送HTTP请求，
    分析响应的数据，获取其中的所有超链接，然后继续向这些超链接地址发送HTTP请求... 通过特定的
    算法，一层一层地爬遍所有的超链接，获取特定的数据；
</code></pre><h2 id="Web静态服务器"><a href="#Web静态服务器" class="headerlink" title="Web静态服务器"></a>Web静态服务器</h2><pre><code>早期的Web服务器资源都是静态的，也即，在服务器上存放开发好的HTML网页等资源，供客户端访问；
静态Web的交互性差；

1. 创建server socket服务
</code></pre><p><img src="http://i.imgur.com/VIgI32F.jpg" alt></p>
<pre><code>2. 为客户端服务的进程target=handle_client
</code></pre><p><img src="http://i.imgur.com/9YDKCAL.jpg" alt></p>
<pre><code>3. 处理数据的函数handle_data()
</code></pre><p><img src="http://i.imgur.com/hPqiJpI.jpg" alt></p>
<pre><code>1. 在当前项目的res目录下，创建index.html文件，并把res目录设置为静态网页的根目录；
2. 在本机上访问：127.0.0.1:8899，设置为访问默认主页，等效于：127.0.0.1:8899/index.html
</code></pre><h3 id="文件读写方式的区别"><a href="#文件读写方式的区别" class="headerlink" title="文件读写方式的区别"></a>文件读写方式的区别</h3><pre><code>open() 规定的读写模式：&quot;r&quot;/&quot;w&quot; 表示文本方式打开/写入，&quot;rb&quot;/&quot;wb&quot; 表示二进制方式打开/写入；
不同系统的换行符可能是不同的：
    1. Unix/Linux： \n
    2. Mac：老版本是 \r，新版本是 \n
    3. windows： \r\n
1. 文本方式写入(w)时，会识别数据中的换行符，并替换成当前系统的换行符，比如写入数据&quot;HI\nDD&quot;，
在windows系统下，数据中&quot;\n&quot;会被替换成&quot;\r\n&quot;；虽然以文本方式读取(r)时，&quot;\r\n&quot;又被转为&quot;\n&quot;，
也即，读取的数据仍是&quot;HI\nDD&quot;，但以二进制方式读取(rb)时，可以发现数据却是&quot;HI\r\nDD&quot;；
2. 二进制方式写入(wb)是，则不会识别任何转义字符，统一作为二进制流进行读写。
</code></pre><h2 id="Web动态服务器"><a href="#Web动态服务器" class="headerlink" title="Web动态服务器"></a>Web动态服务器</h2><pre><code>1. URL地址请求的不再是一个静态网页，而是运行一个python脚本，生成响应的数据；
2. 为了让python-web服务器便于统一调用，python脚本的编写必须符合WSGI规范。
3. WSGI：Python Web Server Gateway Interface
    1. 用于约束python-web服务器和python-web框架的对接规则；
    2. 所有的现代python-web框架都已具备了WSGI接口，web服务器也必须具备WSGI接口，才能确保在
       不修改服务器代码的情况下，可以让web服务器和不同的web架构协同工作。
</code></pre><p><img src="http://i.imgur.com/6qhfqDi.jpg" alt></p>
<pre><code>python脚本中，WSGI标准的HTTP处理函数：
</code></pre><p><img src="http://i.imgur.com/XGFDuaI.jpg" alt></p>
<pre><code>1. 函数的参数：
    environ：必须是字典类型，脚本程序可能需要一些客户端的请求数据，比如客户端的请求方式、提交
            的参数等等，web服务器解析请求数据之后，组织成一个字典，传递给该函数；
    start_response：一个定义在web服务器中的WSGI接口函数，用于接收python脚本传递的响应码和
                部分响应头，从而在web服务器中组织成完整的响应头；
        形参1：响应的状态码，必须是字符串类型
        形参2：部分响应头，必须是一个列表[(键, 值), (键, 值), ...]
2. 函数必须要有返回值，作为响应体；
3. application() 函数就是由web服务器调用的接口，它把底层web服务器的解析部分和应用程序的逻辑
   部分进行分离，只专注于处理程序的逻辑，而程序的逻辑又决定了响应码、部分响应头、以及响应体；
4. 函数名和参数名都是自定义的，但所代表的意义必须符合WSGI标准，web服务器才能正确调用；
5. application() 不一定是函数，重写类中的 __call__() 方法，类对象也可以像调用函数一样使用。
</code></pre><h3 id="改造静态Web"><a href="#改造静态Web" class="headerlink" title="改造静态Web"></a>改造静态Web</h3><pre><code>在静态web服务器的基础上，增加WSGI标准的接口，判断客户端请求的资源是不是一个python脚本，改造成
一个动态Web服务器：
1. 在Web服务器的根目录下，创建存放python脚本的目录wsgipy，并设置 ./wsgipy 目录为脚本资源的
   根目录；在wsgipy目录下创建一个python脚本m_time.py，提供WSGI标准的接口：
</code></pre><p><img src="http://i.imgur.com/E4HrXkT.jpg" alt></p>
<pre><code>2. 在Web服务器中提供WSGI标准的接口，用于拼接完整的响应头：
</code></pre><p><img src="http://i.imgur.com/fVMI2AL.jpg" alt></p>
<pre><code>3. 在Web服务器中处理请求数据时，先判断请求的资源是哪种类型：python脚本，html网页
   如果是python脚本，表示客户端访问的是动态web数据；如果是html网页，表示访问的是静态web数据
</code></pre><p><img src="http://i.imgur.com/dKrFHI4.jpg" alt></p>
<pre><code>在本机的浏览器上输入：127.0.0.1:8899/m_time.py，访问一个动态的web
</code></pre><h2 id="Web框架的编写"><a href="#Web框架的编写" class="headerlink" title="Web框架的编写"></a>Web框架的编写</h2><pre><code>1. 一个web服务器下可能有很多个python脚本和静态HTML网页，每个资源脚本又都有自己的WSGI接口，
   web框架也是python脚本，它提供了WSGI接口，作为所有资源文件的入口；
2. web服务器不关心web框架的实现过程，只需要解析客户端的请求数据，把请求方式、请求的资源路径、
   提交的参数等数据组装成一个字典，并提供WSGI接口，就可以调用web框架的接口，获取响应数据；

4. web框架使用一个类作为WSGI接口，重写类的 __call__()方法，就可以把类的对象改造成一个标准的
   WSGI接口函数；
5. 为了便于区分脚本资源和静态资源，在客户端访问web服务器的静态资源时，资源路径必须以/static为
   根路径，比如：127.0.0.1:8899/static/index.html；
</code></pre><h3 id="web框架"><a href="#web框架" class="headerlink" title="web框架"></a>web框架</h3><p><img src="http://i.imgur.com/o1Nq0Pu.jpg" alt></p>
<p><img src="http://i.imgur.com/DVcxCnM.jpg" alt></p>
<p><img src="http://i.imgur.com/VXJ4DyE.jpg" alt></p>
<pre><code>1. 客户端访问脚本文件时，指定为 urls 中的路径即可，比如：127.0.0.1:8899/ctime；
2. web服务器需要增加新的脚本文件时，只需要在web框架中增加相应的处理函数，并在 urls 中添加相应
   的路径即可，不需要再创建新的脚本，也不需要修改web服务器和web框架的接口Application。
</code></pre><h3 id="web服务器"><a href="#web服务器" class="headerlink" title="web服务器"></a>web服务器</h3><pre><code>面向对象的方式设计web服务器：
</code></pre><p><img src="http://i.imgur.com/e9rpJ2A.jpg" alt></p>
<p><img src="http://i.imgur.com/RfCqlMf.jpg" alt></p>
<pre><code>启动web服务器：
</code></pre><p><img src="http://i.imgur.com/iYtZQR1.jpg" alt></p>
<pre><code>1. getattr(object, name, [default])：反射机制，获取对象object中的成员；
    1. object：一个对象，动态导入的模块，也被看做是一个对象；
    2. name：字符串类型，object中的成员；
    3. default：可选参数，默认为None，用于设置默认值。
2. hasattr(object, name)：判断object中是否存在成员name；
3. setattr(object, name, value)：设置成员name的值为value。
</code></pre><h3 id="不同web框架的启动"><a href="#不同web框架的启动" class="headerlink" title="不同web框架的启动"></a>不同web框架的启动</h3><pre><code>1. 运行python程序时，可以动态传递参数：python3 python.py arg1 arg2 arg3 ...
2. import sys： sys.argv，获取所有参数[&quot;python.py&quot;, &quot;arg1&quot;, &quot;arg2&quot;, &quot;arg3&quot;, ...]
3. 在启动web服务器时，把web框架的模块名和接口对象名作为参数，就可以在不修改web服务器的情况下，
   运行不同的web框架：
</code></pre><p><img src="http://i.imgur.com/rrSE7Kp.jpg" alt></p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://hellomyshadow.github.io/2017/08/04/python正则表达式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="大麦田怪圈">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大麦田程序猿">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/04/python正则表达式/" itemprop="url">python正则表达式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-04T00:00:00+08:00">
                2017-08-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="re-模块基础"><a href="#re-模块基础" class="headerlink" title="re 模块基础"></a>re 模块基础</h2><pre><code>re 模块：正则表达式模块；
1. result = re.match(pattern, string)：匹配操作
    1. pattern：正则表达式；    string：要匹配的字符串；
    2. match() 匹配的规则：从左向右，返回一个符合规则的Match对象；
    3. 如果匹配成功，则返回一个匹配对象(Match Object)，否则返回None
2. result.group()：获取匹配的数据
    1. result = re.match(&quot;abc&quot;, &quot;abcdef&quot;)
    2. result.group() --&gt; &quot;abc&quot;，匹配成功
</code></pre><h3 id="单字符匹配"><a href="#单字符匹配" class="headerlink" title="单字符匹配"></a>单字符匹配</h3><pre><code>. ：匹配任意一个字符，除了&quot;\n&quot;
    1. re.match(&quot;.&quot;, &quot;abc&quot;) --&gt; &quot;a&quot;
    2. re.match(&quot;..&quot;, &quot;abc&quot;) --&gt; &quot;ab&quot;
[] ：匹配[]中列举的任意一个字符
    1. re.match(&quot;[H]&quot;, &quot;Hello Python&quot;)  --&gt; &quot;H&quot;
    2. re.match(&quot;[012]&quot;, &quot;12345&quot;) --&gt; &quot;1&quot;
    3. 在[]中，&quot;-&quot;代表一个连续的范围，比如：&quot;0-9&quot;，&quot;3-6&quot;，&quot;a-z&quot;
    3. re.match(&quot;[0-9]&quot;, &quot;789&quot;) --&gt; &quot;7&quot;；
[^...] ：对[]中列举的字符取反
    1. re.match(&quot;[^123]&quot;, &quot;789&quot;) --&gt; &quot;7&quot;
    2. re.match(&quot;[^abc]&quot;, &quot;python&quot;) --&gt; &quot;p&quot;
\d ：匹配数字0-9，等价于 &quot;[0-9]&quot;
    1. re.match(&quot;\d&quot;, &quot;123&quot;) --&gt; &quot;1&quot;
    2. re.match(&quot;阿波罗\d号&quot;, &quot;阿波罗3号登月&quot;) --&gt; &quot;阿波罗3号&quot;
\D ：匹配非数字的字符，等价于 &quot;[^0-9]&quot;
\s ：匹配空白，即空格、tab键、\n、\t、\r等，但不包括空字符串
    1. re.match(&quot;\s&quot;, &quot; abc&quot;) --&gt; &quot; &quot;
    2. re.match(&quot;\s&quot;, &quot;\n123&quot;) --&gt; &quot;\n&quot;
\S ：匹配非空白
\w ：匹配 a-z、A-Z、0-9、_、汉字 中的任意一个字符
    1. re.match(&quot;\w&quot;, &quot;abc&quot;) --&gt; &quot;a&quot;
    2. re.match(&quot;\w&quot;, &quot;_Python&quot;) --&gt; &quot;_&quot;
\W ：匹配非\w的字符
</code></pre><h3 id="数量的表示"><a href="#数量的表示" class="headerlink" title="数量的表示"></a>数量的表示</h3><pre><code>* ：匹配前一个字符 &gt;=0 次
    1. re.match(&quot;\d*&quot;, &quot;123&quot;) --&gt; &quot;123&quot;，全部匹配
    2. re.match(&quot;\d*&quot;, &quot;abc&quot;) --&gt; &quot;&quot;，0-9的数字出现了 0 次
+ ：匹配前一个字符 &gt;=1 次
    1. re.match(&quot;\d+&quot;, &quot;abc&quot;) --&gt; None，不匹配
    2. re.match(&quot;\d+&quot;, &quot;123&quot;) --&gt; &quot;123&quot;，全部匹配
? ：匹配前一个字符出现 0 或 1 次
    1. re.match(&quot;[0-9]?[1-9]&quot;, &quot;2&quot;) --&gt; &quot;2&quot;
    2. re.match(&quot;[2-8]?[0-9]&quot;, &quot;123&quot;) --&gt; &quot;1&quot;
{m} ：匹配前一个字符出现 m 次
{m,} ：匹配前一个字符至少出现 m 次
{m,n} ：匹配前一个字符出现 [m-n] 次
</code></pre><h3 id="边界的表示"><a href="#边界的表示" class="headerlink" title="边界的表示"></a>边界的表示</h3><pre><code>^ ：匹配字符串开头的第一个字符；
    因为match()本身就是从左向右开始匹配的，所以match()的效果并不明显。
    1. re.match(&quot;^[0-9]abc&quot;, &quot;3abc&quot;) --&gt; 等价于：re.match(&quot;[0-9]abc&quot;, &quot;3abc&quot;)
$ ：匹配结尾的最后一个字符
    1. re.match(&quot;12[0-9]$&quot;, &quot;123&quot;) --&gt; &quot;123&quot;
    2. re.match(&quot;[0-9]$&quot;, &quot;123&quot;) --&gt; None，不匹配
    3. 手机号的正则表达式：&quot;^1[35678]\d{9}$&quot;，匹配的第一个字符为&quot;1&quot;，结尾是9个数字；
    4. re.match(&quot;^1[35678]\d{9}$&quot;, &quot;18111111111&quot;) --&gt; 匹配
    5. re.match(&quot;^1[35678]\d{9}$&quot;, &quot;181111111112&quot;) --&gt; 不匹配
\b ：匹配一个单词边界
    1. 在正则中，所谓的单词，就是由&quot;\w&quot;定义的字符所组成的子串；
    2. &quot;\b&quot; 表示所在位置的一侧为单词字符，另一个为非单词字符、字符串的开始/结束位置；
    3. re.match(&quot;ve\b&quot;, &quot;ve&quot;) --&gt; &quot;ve&quot;
    4. re.match(&quot;ve\b&quot;, &quot;vee&quot;) --&gt; None，不匹配
    5. re.match(&quot;ve\b&quot;, &quot;ve#&quot;) --&gt; &quot;ve&quot;
    6. re.match(&quot;ve\b&quot;, &quot;ve abc&quot;) --&gt; &quot;ve&quot;
\B ：匹配非单词边界
    1. re.match(&quot;.+\Bve\B&quot;, &quot;hove&quot;) --&gt; None，不匹配
    2. re.match(&quot;.+\Bve\B&quot;, &quot;hover&quot;) --&gt; &quot;hove&quot;
</code></pre><h3 id="原始字符串"><a href="#原始字符串" class="headerlink" title="原始字符串"></a>原始字符串</h3><pre><code>原始字符串：在字符串前加 r ，忽略&quot;\&quot;对字符的转义，其实 r 内部对转移字符做了处理；
1. r&quot;\n123&quot; --&gt; 等价于：&quot;\\n123&quot;，print输出：\n123
2. 对于正则中自带的&quot;.&quot;、&quot;*&quot;、&quot;?&quot;等，如果要使用其原生意义，还是需要加&quot;\&quot;；
3. re.match(r&quot;\w+@163\.com&quot;, &quot;isummer@163.com&quot;)
</code></pre><h3 id="匹配分组"><a href="#匹配分组" class="headerlink" title="匹配分组"></a>匹配分组</h3><pre><code>| ：匹配左右任意一个表达式
    1. 匹配0~100之间的数字：&quot;[1-9]?\d$|100&quot;，&quot;[1-9]\d?$|0$|100$&quot;
(ab)：将()中的字符作为一个分组
    1. re.match(r&quot;\w{4,20}@(163|126|qq)\.com$&quot;, &quot;test@163.com&quot;) --&gt; 匹配邮箱；
    2. 提取分组
        1. result = re.match(r&quot;&lt;h1&gt;(.*)&lt;h1&gt;&quot;, &quot;&lt;h1&gt;test&lt;h1&gt;&quot;)
        2. result.group(0) --&gt; 等效于 result.group()
        3. result.group(1)：获取第一个匹配的分组，&quot;test&quot;
        4. result.groups()：获取所有匹配的分组，并返回一个元组；
\num ：与(ab)配合使用，引用第num组匹配的字符串
    1. 匹配超文本字符串：s = &quot;&lt;html&gt;&lt;h1&gt;python&lt;/h1&gt;&lt;/html&gt;&quot;
    2. result = re.match(r&quot;&lt;(.+)&gt;&lt;(.+)&gt;.+&lt;/\2&gt;&lt;\1&gt;&quot;, s)
    3. result.groups() --&gt; (&quot;html&quot;, &quot;h1&quot;)
(?P&lt;name&gt;···)：为分组定义一个名字name
(?P=name)：按照名字name引用分组所匹配的字符串
    1. 匹配超文本字符串：s = &quot;&lt;html&gt;&lt;h1&gt;python&lt;/h1&gt;&lt;/html&gt;&quot;
    2. re.match(r&quot;&lt;(?P&lt;key1&gt;\w*)&gt;&lt;(?P&lt;key2&gt;\w*)&gt;.*&lt;/(?P=key2)&gt;&lt;/(?P=key1)&gt;&quot;, s)
</code></pre><h2 id="re-模块高级"><a href="#re-模块高级" class="headerlink" title="re 模块高级"></a>re 模块高级</h2><pre><code>1. search(pattern, str)
    1. 从左向右，查找出符合pattern的第一个子串，也返回Match对象；
    2. re.search(r&quot;\d+&quot;, &quot;read 9999 times 2222&quot;) --&gt; &quot;9999&quot;
    3. re.match(r&quot;\d+&quot;, &quot;read 9999 times 2222&quot;) --&gt; None
    4. 区别：match()从字符串开头进行匹配，如果匹配失败，则返回None；而search()会查找
    字符串中符合规则的字串，如果没有，才返回None；
    5. 共同点：只匹配一次，返回匹配成功的第一个字串。
1. Match.span()：返回一个元组，元素是成功匹配的开始角标和结束角标；
2. findall(pattern, str)：查找出str中所有符合pattern的子串，返回一个列表；
    1. re.findall(r&quot;\d+&quot;, &quot;read 9999 times 2222&quot;) --&gt; [&quot;9999&quot;, &quot;2222&quot;]
    2. finditer()：与findall()的区别，返回一个迭代器，元素是Match对象。
3. sub(pattern, repl, str)
    1. 批量替换：查找出符合pattern的所有子串，替换成repl，返回一个新的字符串；
    2. re.sub(r&quot;\d+&quot;, &quot;50&quot;, &quot;read 99 times 22&quot;) --&gt; &quot;read 50 times 50&quot;
    3. repl 可以接收一个函数：
        1. 函数必须要有一个形参，用于接收每次匹配成功所返回的Match对象；
        2. 匹配的子串会被替换成函数的返回值，所以函数的返回值必须是字符串；
        3. 如果函数没有return，默认返回为空字符串；
</code></pre><p><img src="http://i.imgur.com/UmS62S4.jpg" alt></p>
<pre><code>4. split(pattern, string)
    1. 根据pattern切割字符串，返回一个列表；
    2. re.split(r&quot;:| &quot;, &quot;python:Java php C&quot;) --&gt; [&quot;python&quot;, &quot;Java&quot;, &quot;php&quot;, &quot;C&quot;]
</code></pre><h3 id="贪婪模式"><a href="#贪婪模式" class="headerlink" title="贪婪模式"></a>贪婪模式</h3><pre><code>1. 在Python中，数量词默认是贪婪的，总是尝试匹配尽可能多的字符；非贪婪模式则相反，总是尝试
   匹配尽可能少的字符；
2. 正则表达式中的数量词：&quot;*&quot;，&quot;?&quot;，&quot;+&quot;
3. 贪婪模式转为非贪婪模式：在数量词后加上 &quot;?&quot;
</code></pre><p><img src="http://i.imgur.com/f0D1bUD.jpg" alt></p>
<pre><code>s = &quot;&lt;p&gt;Hello Python&lt;/p&gt;&quot;
1. 贪婪模式：re.sub(r&quot;&lt;.+&gt;&quot;, &quot;==&quot;, s) --&gt; &quot;==&quot;
2. 非贪婪模式：re.sub(r&quot;&lt;.+?&gt;&quot;, &quot;==&quot;, s) --&gt; &quot;==Hello Python==&quot;
</code></pre><h3 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h3><pre><code>compile(pattern)：创建一个pattern对象，可以调用match(str)，search(str) ...
1. match/search(str, begin, end)：可以指定匹配的范围，返回Match对象；
2. re.S：全文匹配；    re.I：忽略大小写；
    1. p = re.compile(&apos;&lt;div\sclass=&quot;content&quot;&gt;(.*?)&lt;/div&gt;&apos;, re.S)
    2. p.findall(htmlstr)：自动提取匹配成功后的分组，返回的列表元素是分组(.*?)
</code></pre><hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">大麦田怪圈</p>
              <p class="site-description motion-element" itemprop="description">敢做就能赢！</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">53</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">大麦田怪圈</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
